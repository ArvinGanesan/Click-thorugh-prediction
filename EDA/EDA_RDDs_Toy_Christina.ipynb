{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W261 Final Project\n",
    "\n",
    "#### *Anusha Munjuluri, Arvindh Ganesan, Kim Vignola, Christina Papadimitriou*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql import types\n",
    "import pyspark.sql\n",
    "import pyspark.sql.functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store path to notebook\n",
    "PWD = !pwd\n",
    "PWD = PWD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"final_project\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Question Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA & Discussion of Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t1\t1\t5\t0\t1382\t4\t15\t2\t181\t1\t2\t\t2\t68fd1e64\t80e26c9b\tfb936136\t7b4723c4\t25c83c98\t7e0ccccf\tde7995b8\t1f89b562\ta73ee510\ta8cd5504\tb2cb9c98\t37c9c164\t2824a5f6\t1adce6ef\t8ba8b39a\t891b62e7\te5ba7672\tf54016b9\t21ddcdc9\tb1252a9d\t07b5194c\t\t3a171ecb\tc5c50484\te8b83407\t9727dd16\n"
     ]
    }
   ],
   "source": [
    "# take a look at the data\n",
    "!head -n 1 data/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "fullTrainRDD = sc.textFile('data/train.txt')\n",
    "testRDD = sc.textFile('data/test.txt')\n",
    "\n",
    "FIELDS = ['I1','I2','I3','I4','I5','I6','I7','I8','I9','I10','I11','I12','I13',\n",
    "          'C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14',\n",
    "          'C15','C16','C17','C18','C19','C20','C21','C22','C23','C24','C25','C26','Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in train data: 45840617 ...\n",
      "Number of records in test data: 6042135 ...\n"
     ]
    }
   ],
   "source": [
    "# number of rows in train/test data\n",
    "print(f\"Number of records in train data: {fullTrainRDD.count()} ...\")\n",
    "print(f\"Number of records in test data: {testRDD.count()} ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creating Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... held out 9167871 records for evaluation and assigned 36672746 for training.\n"
     ]
    }
   ],
   "source": [
    "# Generate 80/20 (pseudo)random train/test split \n",
    "trainRDD, heldOutRDD = fullTrainRDD.randomSplit([0.8,0.2], seed = 1)\n",
    "print(f\"... held out {heldOutRDD.count()} records for evaluation and assigned {trainRDD.count()} for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def parse(line):\n",
    "    \"\"\"\n",
    "    Map line --> tuple of (features, label)\n",
    "    \"\"\"\n",
    "    fields = line.split('\\t')\n",
    "    features,label = fields[1:], fields[0]\n",
    "    return(features, label)\n",
    "\n",
    "def edit_data_types(line):\n",
    "    \"\"\"\n",
    "    Map tuple of (features, label) --> tuple of (formated features, label)\n",
    "    \n",
    "    * '' is replaced with NaN\n",
    "    * numerical fields are converted to integers\n",
    "    * make label column numeric\n",
    "    \"\"\"\n",
    "    features, label = line[0], line[1]\n",
    "    formated_features = []\n",
    "    for i, value in enumerate(features):\n",
    "        if value == '':\n",
    "            formated_features.append('null') # replaced the np.nan with 'null' because spark doesnt recognize np.nan when filtering\n",
    "        else:\n",
    "            if i < 13:\n",
    "                formated_features.append(float(value)) \n",
    "            else:\n",
    "                formated_features.append(value)\n",
    "    return (formated_features, int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing, making '' as np.nan and converting numerical features and output label to int\n",
    "trainRDDCached = trainRDD.map(parse).map(edit_data_types).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([1.0, 1.0, 5.0, 0.0, 1382.0, 4.0, 15.0, 2.0, 181.0, 1.0, 2.0, 'null', 2.0, '68fd1e64', '80e26c9b', 'fb936136', '7b4723c4', '25c83c98', '7e0ccccf', 'de7995b8', '1f89b562', 'a73ee510', 'a8cd5504', 'b2cb9c98', '37c9c164', '2824a5f6', '1adce6ef', '8ba8b39a', '891b62e7', 'e5ba7672', 'f54016b9', '21ddcdc9', 'b1252a9d', '07b5194c', 'null', '3a171ecb', 'c5c50484', 'e8b83407', '9727dd16'], 0)]\n"
     ]
    }
   ],
   "source": [
    "print(trainRDDCached.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Creating a toy RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating toy sample (run this once from cmd line and reuse the same sample)\n",
    "# !gshuf -n 1000 data/train.txt >> data/toy1000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in toy data: 1000 ...\n"
     ]
    }
   ],
   "source": [
    "toyRDD = sc.textFile('data/toy1000.txt')\n",
    "toyRDDCached = toyRDD.map(parse).map(edit_data_types).cache()\n",
    "\n",
    "print(f\"Number of records in toy data: {toyRDDCached.count()} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([0.0, 478.0, 13.0, 'null', 3396.0, 194.0, 11.0, 13.0, 312.0, 0.0, 7.0, 'null', 'null', '05db9164', '207b2d81', '1757640a', '06148e59', '25c83c98', 'fbad5c96', 'f36791d8', '0b153874', 'a73ee510', 'c7009b63', '2714650d', '1a69f1c0', '9a88e2e2', '07d13a8f', '0c67c4ca', '8075af0c', 'e5ba7672', '395856b0', '21ddcdc9', 'b1252a9d', '8e4884c0', 'null', '423fab69', 'b936bfbe', '001f3601', 'f2fc1d6e'], 1)]\n"
     ]
    }
   ],
   "source": [
    "print(toyRDDCached.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -------------------------------------------------------------------------------------------------------------------\n",
    "#### !!!! For the below analysis `toyRDD` can be replaced by `trainRDDCached` to run the processing on the entire dataset\n",
    "#### -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.3 % of the records have label=0 and 27.7 % have label=1...\n"
     ]
    }
   ],
   "source": [
    "# TOY DATA\n",
    "# counting records for each class \n",
    "count_label_0 = toyRDDCached.filter(lambda x: x[1] == 0).count()\n",
    "count_label_1 = toyRDDCached.filter(lambda x: x[1] == 1).count()\n",
    "total = count_label_0 + count_label_1\n",
    "\n",
    "print(f\"{np.round(count_label_0/total*100, 2)} % of the records have label=0 and {np.round(count_label_1/total*100, 2)} % have label=1...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.38 % of the records have label=0 and 25.62 % have label=1...\n"
     ]
    }
   ],
   "source": [
    "# FULL DATA\n",
    "# counting records for each class \n",
    "count_label_0 = trainRDDCached.filter(lambda x: x[1] == 0).count()\n",
    "count_label_1 = trainRDDCached.filter(lambda x: x[1] == 1).count()\n",
    "total = count_label_0 + count_label_1\n",
    "\n",
    "print(f\"{np.round(count_label_0/total*100, 2)} % of the records have label=0 and {np.round(count_label_1/total*100, 2)} % have label=1...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Takeaway: labels are imbalanced, with 75% of records having label=0 (i.e. unclicked ads). However, we will not attempt to balance the labels at this stage. Being aware of this imbalance, we will carefully examine the prediction results to detect any bias (i.e. predicting always label=0)**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Counting nulls in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pct_nulls_in_column(dataRDD, var_position):\n",
    "    \"\"\"\n",
    "    Counts the % nulls in a column \n",
    "    \"\"\"\n",
    "\n",
    "    null_count = dataRDD.map(lambda x: x[0][var_position]) \\\n",
    "                             .filter(lambda x: x == 'null').count()\n",
    "    total_count = dataRDD.map(lambda x: x[0][var_position]).count()\n",
    "\n",
    "    return null_count/total_count*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE I1: 43.2% is null\n",
      "FEATURE I2: 0.0% is null\n",
      "FEATURE I3: 21.3% is null\n",
      "FEATURE I4: 22.1% is null\n",
      "FEATURE I5: 2.4% is null\n",
      "FEATURE I6: 23.0% is null\n",
      "FEATURE I7: 3.7% is null\n",
      "FEATURE I8: 0.0% is null\n",
      "FEATURE I9: 3.7% is null\n",
      "FEATURE I10: 43.2% is null\n",
      "FEATURE I11: 3.7% is null\n",
      "FEATURE I12: 77.4% is null\n",
      "FEATURE I13: 22.1% is null\n",
      "FEATURE C1: 0.0% is null\n",
      "FEATURE C2: 0.0% is null\n",
      "FEATURE C3: 3.4% is null\n",
      "FEATURE C4: 3.4% is null\n",
      "FEATURE C5: 0.0% is null\n",
      "FEATURE C6: 13.4% is null\n",
      "FEATURE C7: 0.0% is null\n",
      "FEATURE C8: 0.0% is null\n",
      "FEATURE C9: 0.0% is null\n",
      "FEATURE C10: 0.0% is null\n",
      "FEATURE C11: 0.0% is null\n",
      "FEATURE C12: 3.4% is null\n",
      "FEATURE C13: 0.0% is null\n",
      "FEATURE C14: 0.0% is null\n",
      "FEATURE C15: 0.0% is null\n",
      "FEATURE C16: 3.4% is null\n",
      "FEATURE C17: 0.0% is null\n",
      "FEATURE C18: 0.0% is null\n",
      "FEATURE C19: 42.2% is null\n",
      "FEATURE C20: 42.2% is null\n",
      "FEATURE C21: 3.4% is null\n",
      "FEATURE C22: 74.5% is null\n",
      "FEATURE C23: 0.0% is null\n",
      "FEATURE C24: 3.4% is null\n",
      "FEATURE C25: 42.2% is null\n",
      "FEATURE C26: 42.2% is null\n"
     ]
    }
   ],
   "source": [
    "# TOY DATA\n",
    "for var_position, var in enumerate(FIELDS):\n",
    "\n",
    "    if var_position < 39:\n",
    "        null_pct = get_pct_nulls_in_column(toyRDDCached, var_position)\n",
    "        print(\"FEATURE {}: {}% is null\".format(var, np.round(null_pct,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL DATA\n",
    "for var_position, var in enumerate(FIELDS):\n",
    "\n",
    "    if var_position < 39:\n",
    "        null_pct = get_pct_nulls_in_column(trainRDDCached, var_position)\n",
    "        print(\"FEATURE {}: {}% is null\".format(var, np.round(null_pct,2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Takeaway: some columns have a high % of null values. We could exclude columns that have more than 50% nulls because those columns will likely not contribute to the prediction results. However, since those variables with more than 50% missing values are categorical variables, the one-hot encoding approach that we will take later on will take care of those missing values**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Numeric Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7.1 Get statistics and impute nulls with means/medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(dataRDD, var_position):\n",
    "    \"\"\"\n",
    "    Get statistics for numeric variables \n",
    "    stats: mean, median, variance, min, max \n",
    "    \"\"\"\n",
    "\n",
    "    mean = dataRDD.map(lambda x: x[0][var_position]).filter(lambda x: x != 'null').mean() \n",
    "    variance = dataRDD.map(lambda x: x[0][var_position]).filter(lambda x: x != 'null').variance() \n",
    "    minimum = dataRDD.map(lambda x: x[0][var_position]).filter(lambda x: x != 'null').min() \n",
    "    maximum = dataRDD.map(lambda x: x[0][var_position]).filter(lambda x: x != 'null').max() \n",
    "\n",
    "    return mean, variance, minimum, maximum\n",
    "\n",
    "\n",
    "def impute_nulls(line, mean_dict):\n",
    "    \"\"\"\n",
    "    Impute the null values of the numerical columns with the mean value of the column\n",
    "    \"\"\"\n",
    "    features, label = line[0], line[1]\n",
    "    imputed_features = []\n",
    "    for i, value in enumerate(features):\n",
    "        if i < 13: \n",
    "            if value == 'null':\n",
    "                imputed_features.append(mean_dict[i])\n",
    "            else:\n",
    "                imputed_features.append(value)\n",
    "        else: \n",
    "            imputed_features.append(value)\n",
    "    return (imputed_features, int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE I1: \t mean=3.17, \t variance=33.98, \t min=0.0, \t max=55.0\n",
      "FEATURE I2: \t mean=114.72, \t variance=179230.84, \t min=-2.0, \t max=5123.0\n",
      "FEATURE I3: \t mean=18.78, \t variance=2026.69, \t min=0.0, \t max=648.0\n",
      "FEATURE I4: \t mean=7.43, \t variance=86.02, \t min=0.0, \t max=77.0\n",
      "FEATURE I5: \t mean=18392.77, \t variance=4908735552.87, \t min=0.0, \t max=1002457.0\n",
      "FEATURE I6: \t mean=95.23, \t variance=65007.31, \t min=0.0, \t max=4304.0\n",
      "FEATURE I7: \t mean=17.94, \t variance=8794.35, \t min=0.0, \t max=2614.0\n",
      "FEATURE I8: \t mean=12.96, \t variance=183.6, \t min=0.0, \t max=49.0\n",
      "FEATURE I9: \t mean=102.42, \t variance=38152.34, \t min=0.0, \t max=2711.0\n",
      "FEATURE I10: \t mean=0.64, \t variance=0.5, \t min=0.0, \t max=4.0\n",
      "FEATURE I11: \t mean=2.78, \t variance=23.83, \t min=0.0, \t max=60.0\n",
      "FEATURE I12: \t mean=1.19, \t variance=40.19, \t min=0.0, \t max=84.0\n",
      "FEATURE I13: \t mean=7.99, \t variance=116.35, \t min=0.0, \t max=97.0\n"
     ]
    }
   ],
   "source": [
    "# TOY DATA\n",
    "\n",
    "# save the means in a dictionary\n",
    "mean_dict_toy = {}\n",
    "st_dev_dict_toy = {}\n",
    "\n",
    "for var_position, var in enumerate(FIELDS):\n",
    "    if var_position < 13:\n",
    "        mean, variance, minimum, maximum = get_stats(toyRDDCached, var_position)\n",
    "        print(\"FEATURE {}: \\t mean={}, \\t variance={}, \\t min={}, \\t max={}\".format(var, np.round(mean, 2), np.round(variance, 2), minimum, maximum))\n",
    "        mean_dict_toy[var_position] = mean\n",
    "        st_dev_dict_toy[var_position] = np.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL DATA\n",
    "\n",
    "# save the means in a dictionary\n",
    "mean_dict = {}\n",
    "st_dev_dict = {}\n",
    "\n",
    "for var_position, var in enumerate(FIELDS):\n",
    "    if var_position < 13:\n",
    "        mean, variance, minimum, maximum = get_stats(trainRDDCached, var_position)\n",
    "        print(\"FEATURE {}: mean={}, variance={}, min={}, max={}\".format(var, np.round(mean, 2), np.round(variance, 2), minimum, maximum))\n",
    "        mean_dict[var_position] = mean\n",
    "        st_dev_dict_toy[var_position] = np.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing nulls with mean \n",
    "\n",
    "# TOY DATA\n",
    "imputedToyRDDCached = toyRDDCached.map(lambda x: impute_nulls(x, mean_dict_toy)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL DATA \n",
    "imputedTrainRDDCached = trainRDDCached.map(lambda x: impute_nulls(x, mean_dict)).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Takeaway: we impute the null values of the numerical columns with the mean (or median) of that column. No need to do that for the categorical features since one hot encoding will take care of the nulls.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7.2 Standardize features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(line, mean_dict, st_dev_dict):\n",
    "    \"\"\"\n",
    "    Scale and center data round mean of each feature (mean=0, sd=1)\n",
    "    \"\"\"\n",
    "    features, label = line[0], line[1]\n",
    "    formated_features = []\n",
    "    for i, value in enumerate(features):\n",
    "        if i < 13: \n",
    "            formated_features.append((value-mean_dict[i])/st_dev_dict[i])\n",
    "        else: \n",
    "            formated_features.append(value)\n",
    "\n",
    "    return (formated_features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOY DATA \n",
    "normedToyRDDCached = imputedToyRDDCached.map(lambda x: standardize(x, mean_dict_toy, st_dev_dict_toy)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL DATA \n",
    "normedRDDCached = imputedTrainRDDCached.map(lambda x: standardize(x, mean_dict, st_dev_dict)).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Takeaway: In the summary statistics, we notice that the numerical features have different ranges and thus we standardize our data (i.e. subtracting by the mean and dividing by the standard deviation of each column. Standardization would also help for a Logistic Regression algorithm to coverge faster.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will perform data processing on the 26 categorical features of the dataset. We will start by performing some EDA to compute the **number of unique categories** within each categorical feature and the total counts for each category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_categories(dataRDD, var, var_position, top):\n",
    "    \"\"\"\n",
    "    input: RDD, name and position of a categorical variable \n",
    "    \n",
    "    output: \n",
    "    * number of unique categories in the variable\n",
    "    * counts of each category occurance by label\n",
    "    \"\"\"\n",
    "    \n",
    "    # counting category occurance within each categorical feature \n",
    "    count_per_category = dataRDD.map(lambda x: ( x[0][var_position], 1)) \\\n",
    "                                           .reduceByKey(lambda x,y: x+y) \\\n",
    "                                           .sortBy(lambda x: -x[1])\n",
    "\n",
    "    # counting number of unique values within the categorical variable\n",
    "    num_unique_values = count_per_category.map(lambda x: x[0]).distinct().count()\n",
    "\n",
    "    print('Unique values within the category:', num_unique_values)\n",
    "    print(' ')\n",
    "    top_x = count_per_category.take(top)\n",
    "    print('Top {} categories by count:'.format(top))\n",
    "    for i in top_x: \n",
    "        print('Category: {}; Count: {}'.format(i[0],i[1]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "VARIABLE C1\n",
      " \n",
      "Unique values within the category: 57\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: 05db9164; Count: 485\n",
      "Category: 68fd1e64; Count: 146\n",
      "Category: 5a9ed9b0; Count: 103\n",
      "Category: 8cf07265; Count: 51\n",
      "Category: be589b51; Count: 41\n",
      "Category: 5bfa8ab5; Count: 27\n",
      "Category: f473b8dc; Count: 20\n",
      "Category: 87552397; Count: 15\n",
      "Category: 39af2607; Count: 13\n",
      "Category: 9a89b36c; Count: 9\n",
      " \n",
      " \n",
      "VARIABLE C2\n",
      " \n",
      "Unique values within the category: 193\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: 38a947a1; Count: 114\n",
      "Category: 1cfdf714; Count: 50\n",
      "Category: 287130e0; Count: 46\n",
      "Category: 38d50e09; Count: 46\n",
      "Category: 207b2d81; Count: 37\n",
      "Category: 09e68b86; Count: 33\n",
      "Category: 421b43cd; Count: 33\n",
      "Category: 4f25e98b; Count: 29\n",
      "Category: 89ddfee8; Count: 27\n",
      "Category: 58e67aaf; Count: 27\n",
      " \n",
      " \n",
      "VARIABLE C3\n",
      " \n",
      "Unique values within the category: 771\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: null; Count: 34\n",
      "Category: d032c263; Count: 15\n",
      "Category: 02cf9876; Count: 13\n",
      "Category: b00d1501; Count: 12\n",
      "Category: 77f2f2e5; Count: 10\n",
      "Category: aa8c1539; Count: 10\n",
      "Category: 2cbec47f; Count: 8\n",
      "Category: 7da86e4b; Count: 7\n",
      "Category: 9143c832; Count: 7\n",
      "Category: b1ecc6c4; Count: 7\n",
      " \n",
      " \n",
      "VARIABLE C4\n",
      " \n",
      "Unique values within the category: 660\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: null; Count: 34\n",
      "Category: 29998ed1; Count: 28\n",
      "Category: c18be181; Count: 28\n",
      "Category: d16679b9; Count: 25\n",
      "Category: 85dd697c; Count: 17\n",
      "Category: 13508380; Count: 15\n",
      "Category: f922efad; Count: 14\n",
      "Category: e3cc371a; Count: 8\n",
      "Category: 3e2bfbda; Count: 8\n",
      "Category: b733e495; Count: 7\n",
      " \n",
      " \n",
      "VARIABLE C5\n",
      " \n",
      "Unique values within the category: 26\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: 25c83c98; Count: 653\n",
      "Category: 4cf72387; Count: 170\n",
      "Category: 43b19349; Count: 56\n",
      "Category: 384874ce; Count: 41\n",
      "Category: 0942e0a7; Count: 17\n",
      "Category: 30903e74; Count: 17\n",
      "Category: f281d2a7; Count: 13\n",
      "Category: b0530c50; Count: 7\n",
      "Category: b2241560; Count: 6\n",
      "Category: 26eb6185; Count: 2\n",
      " \n",
      " \n",
      "VARIABLE C6\n",
      " \n",
      "Unique values within the category: 7\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: 7e0ccccf; Count: 388\n",
      "Category: fbad5c96; Count: 207\n",
      "Category: fe6b92e5; Count: 185\n",
      "Category: null; Count: 134\n",
      "Category: 6f6d9be8; Count: 37\n",
      "Category: 13718bbd; Count: 28\n",
      "Category: 3bf701e7; Count: 21\n",
      " \n",
      " \n",
      "VARIABLE C7\n",
      " \n",
      "Unique values within the category: 723\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: 1c86e0eb; Count: 30\n",
      "Category: 7195046d; Count: 12\n",
      "Category: 90a2c015; Count: 10\n",
      "Category: 81bb0302; Count: 10\n",
      "Category: 468a0854; Count: 8\n",
      "Category: dc7659bd; Count: 7\n",
      "Category: 5e64ce5f; Count: 6\n",
      "Category: d2dbdfe6; Count: 6\n",
      "Category: f00bddf8; Count: 6\n",
      "Category: 88002ee1; Count: 6\n",
      " \n",
      " \n",
      "VARIABLE C8\n",
      " \n",
      "Unique values within the category: 35\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: 0b153874; Count: 597\n",
      "Category: 5b392875; Count: 163\n",
      "Category: 1f89b562; Count: 69\n",
      "Category: 37e4aa92; Count: 37\n",
      "Category: 51d76abe; Count: 25\n",
      "Category: 062b5529; Count: 20\n",
      "Category: c8ddd494; Count: 12\n",
      "Category: 6c41e35e; Count: 12\n",
      "Category: 985e3fcb; Count: 10\n",
      "Category: 64523cfa; Count: 8\n",
      " \n",
      " \n",
      "VARIABLE C9\n",
      " \n",
      "Unique values within the category: 2\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: a73ee510; Count: 900\n",
      "Category: 7cc72ec2; Count: 100\n",
      " \n",
      " \n",
      "VARIABLE C10\n",
      " \n",
      "Unique values within the category: 613\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: 3b08e48b; Count: 216\n",
      "Category: fbbf2c95; Count: 16\n",
      "Category: 5ba575e7; Count: 10\n",
      "Category: efea433b; Count: 10\n",
      "Category: 67eea4ef; Count: 6\n",
      "Category: 49d1ad89; Count: 5\n",
      "Category: 03e48276; Count: 5\n",
      "Category: 474773a7; Count: 5\n",
      "Category: f9065d00; Count: 5\n",
      "Category: 935a36f0; Count: 5\n",
      " \n",
      " \n",
      "VARIABLE C11\n",
      " \n",
      "Unique values within the category: 601\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: 755e4a50; Count: 36\n",
      "Category: 4d8549da; Count: 15\n",
      "Category: 7f8ffe57; Count: 14\n",
      "Category: e51ddf94; Count: 14\n",
      "Category: b7094596; Count: 11\n",
      "Category: 1054ae5c; Count: 10\n",
      "Category: a7b606c4; Count: 10\n",
      "Category: 8b94178b; Count: 9\n",
      "Category: 0f736a0c; Count: 9\n",
      "Category: 7e40f08a; Count: 8\n",
      " \n",
      " \n",
      "VARIABLE C12\n",
      " \n",
      "Unique values within the category: 736\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: null; Count: 34\n",
      "Category: 6aaba33c; Count: 28\n",
      "Category: dfbb09fb; Count: 15\n",
      "Category: 8fe001f4; Count: 13\n",
      "Category: e0d76380; Count: 12\n",
      "Category: 9f32b866; Count: 10\n",
      "Category: d8c29807; Count: 10\n",
      "Category: 21a23bfe; Count: 8\n",
      "Category: ed397d6b; Count: 7\n",
      "Category: ae1bb660; Count: 7\n",
      " \n",
      " \n",
      "VARIABLE C13\n",
      " \n",
      "Unique values within the category: 549\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: 5978055e; Count: 36\n",
      "Category: 3516f6e6; Count: 16\n",
      "Category: 51b97b8f; Count: 15\n",
      "Category: 1aa94af3; Count: 14\n",
      "Category: 46f42a63; Count: 14\n",
      "Category: 740c210d; Count: 12\n",
      "Category: 025225f2; Count: 11\n",
      "Category: 1f9d2c38; Count: 11\n",
      "Category: 6e5da64f; Count: 10\n",
      "Category: eae197fd; Count: 10\n",
      " \n",
      " \n",
      "VARIABLE C14\n",
      " \n",
      "Unique values within the category: 18\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: b28479f6; Count: 367\n",
      "Category: 07d13a8f; Count: 320\n",
      "Category: 1adce6ef; Count: 156\n",
      "Category: 64c94865; Count: 47\n",
      "Category: cfef1c29; Count: 31\n",
      "Category: 051219e6; Count: 26\n",
      "Category: d2dfe871; Count: 11\n",
      "Category: 8ceecbc8; Count: 11\n",
      "Category: f862f261; Count: 8\n",
      "Category: ad1cc976; Count: 7\n",
      " \n",
      " \n",
      "VARIABLE C15\n",
      " \n",
      "Unique values within the category: 553\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: 2d0bb053; Count: 21\n",
      "Category: d345b1a0; Count: 14\n",
      "Category: 310d155b; Count: 14\n",
      "Category: 42b3012c; Count: 13\n",
      "Category: 52baadf5; Count: 11\n",
      "Category: 10040656; Count: 11\n",
      "Category: f3002fbd; Count: 10\n",
      "Category: 10935a85; Count: 9\n",
      "Category: e1ac77f7; Count: 9\n",
      "Category: 3628a186; Count: 9\n",
      " \n",
      " \n",
      "VARIABLE C16\n",
      " \n",
      "Unique values within the category: 707\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: null; Count: 34\n",
      "Category: b041b04a; Count: 28\n",
      "Category: 84898b2a; Count: 15\n",
      "Category: 36103458; Count: 13\n",
      "Category: 1203a270; Count: 12\n",
      "Category: 31ca40b6; Count: 10\n",
      "Category: c64d548f; Count: 10\n",
      "Category: 587267a3; Count: 8\n",
      "Category: c4de5bba; Count: 8\n",
      "Category: 01adbab4; Count: 7\n",
      " \n",
      " \n",
      "VARIABLE C17\n",
      " \n",
      "Unique values within the category: 9\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: e5ba7672; Count: 497\n",
      "Category: d4bb7bd8; Count: 115\n",
      "Category: 07c540c4; Count: 109\n",
      "Category: 3486227d; Count: 67\n",
      "Category: 1e88c74f; Count: 53\n",
      "Category: 776ce399; Count: 51\n",
      "Category: 8efede7f; Count: 44\n",
      "Category: 27c07bd6; Count: 40\n",
      "Category: 2005abd1; Count: 24\n",
      " \n",
      " \n",
      "VARIABLE C18\n",
      " \n",
      "Unique values within the category: 392\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: e88ffc9d; Count: 43\n",
      "Category: 891589e7; Count: 37\n",
      "Category: 2804effd; Count: 33\n",
      "Category: c21c3e4c; Count: 27\n",
      "Category: 5bb2ec8e; Count: 23\n",
      "Category: 582152eb; Count: 22\n",
      "Category: 5aed7436; Count: 22\n",
      "Category: 7ef5affa; Count: 18\n",
      "Category: 395856b0; Count: 16\n",
      "Category: fffe2a63; Count: 12\n",
      " \n",
      " \n",
      "VARIABLE C19\n",
      " \n",
      "Unique values within the category: 128\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: null; Count: 422\n",
      "Category: 21ddcdc9; Count: 358\n",
      "Category: 55dd3565; Count: 20\n",
      "Category: 712d530c; Count: 9\n",
      "Category: 5b885066; Count: 8\n",
      "Category: 9437f62f; Count: 7\n",
      "Category: cf99e5de; Count: 7\n",
      "Category: 04de9d96; Count: 6\n",
      "Category: 3014a4b1; Count: 5\n",
      "Category: 1d1eb838; Count: 5\n",
      " \n",
      " \n",
      "VARIABLE C20\n",
      " \n",
      "Unique values within the category: 4\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: null; Count: 422\n",
      "Category: a458ea53; Count: 209\n",
      "Category: b1252a9d; Count: 187\n",
      "Category: 5840adea; Count: 182\n",
      " \n",
      " \n",
      "VARIABLE C21\n",
      " \n",
      "Unique values within the category: 724\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: null; Count: 34\n",
      "Category: 723b4dfd; Count: 28\n",
      "Category: 0014c32a; Count: 15\n",
      "Category: e587c466; Count: 13\n",
      "Category: 73d06dde; Count: 12\n",
      "Category: 5f957280; Count: 10\n",
      "Category: dfcfc3fa; Count: 10\n",
      "Category: c2a93b37; Count: 8\n",
      "Category: deaf6b52; Count: 7\n",
      "Category: 0429f84b; Count: 7\n",
      " \n",
      " \n",
      "VARIABLE C22\n",
      " \n",
      "Unique values within the category: 6\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: null; Count: 745\n",
      "Category: ad3062eb; Count: 145\n",
      "Category: c9d4222a; Count: 94\n",
      "Category: 8ec974f4; Count: 7\n",
      "Category: 78e2e389; Count: 6\n",
      "Category: c0061c6d; Count: 3\n",
      " \n",
      " \n",
      "VARIABLE C23\n",
      " \n",
      "Unique values within the category: 12\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: 32c7478e; Count: 447\n",
      "Category: 3a171ecb; Count: 199\n",
      "Category: 423fab69; Count: 111\n",
      "Category: bcdee96c; Count: 81\n",
      "Category: be7c41b4; Count: 63\n",
      "Category: c7dc6720; Count: 47\n",
      "Category: 55dd3565; Count: 20\n",
      "Category: dbb486d7; Count: 16\n",
      "Category: c3dc6cef; Count: 7\n",
      "Category: 93bad2c0; Count: 5\n",
      " \n",
      " \n",
      "VARIABLE C24\n",
      " \n",
      "Unique values within the category: 489\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: 3fdb382b; Count: 56\n",
      "Category: b34f3128; Count: 50\n",
      "Category: 1793a828; Count: 49\n",
      "Category: null; Count: 34\n",
      "Category: 3b183c5c; Count: 31\n",
      "Category: aee52b6f; Count: 25\n",
      "Category: 45ab94c8; Count: 22\n",
      "Category: 9117a34a; Count: 19\n",
      "Category: df487a73; Count: 16\n",
      "Category: 8fc66e78; Count: 15\n",
      " \n",
      " \n",
      "VARIABLE C25\n",
      " \n",
      "Unique values within the category: 30\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: null; Count: 422\n",
      "Category: 001f3601; Count: 135\n",
      "Category: e8b83407; Count: 112\n",
      "Category: ea9a246c; Count: 84\n",
      "Category: cb079c2d; Count: 44\n",
      "Category: f0f449dd; Count: 35\n",
      "Category: 445bbe3b; Count: 30\n",
      "Category: 010f6491; Count: 29\n",
      "Category: 2bf691b1; Count: 28\n",
      "Category: 9b3e8820; Count: 28\n",
      " \n",
      " \n",
      "VARIABLE C26\n",
      " \n",
      "Unique values within the category: 375\n",
      " \n",
      "Top 10 categories by count:\n",
      "Category: null; Count: 422\n",
      "Category: 49d68486; Count: 38\n",
      "Category: 2fede552; Count: 22\n",
      "Category: c27f155b; Count: 19\n",
      "Category: c84c4aec; Count: 15\n",
      "Category: 984e0db0; Count: 11\n",
      "Category: aa5f0a15; Count: 11\n",
      "Category: b7d9c3bc; Count: 9\n",
      "Category: 6c27a535; Count: 7\n",
      "Category: 56be3401; Count: 6\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# TOY DATA\n",
    "for var_position, var in enumerate(FIELDS):\n",
    "\n",
    "    if var_position > 12 and var_position < 39:\n",
    "        print(\" \")\n",
    "        print(\"VARIABLE {}\".format(var))\n",
    "        print(\" \")\n",
    "        count_categories(normedToyRDDCached, var, var_position=var_position, top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above analysis shows that some categorical variables have a high number of unique categories. Aditionally, the distribution of counts for most of the categorical variables is very skewed (i.e. some categories appear much more often than others). Considering this information, we decided to take the following approach to deal with categorical variables: \n",
    "\n",
    "* Bucket the categories within each categorical feature in 4 groups based on their occurence counts\n",
    "    * **High frequency**: categories that occur more times than 10% of the total row count (Example: if the total row count is 1000 -> categories that occur *more than 100 times*)\n",
    "    * **Medium frequency**: categories that occur more times than 5% and less than 10% of the total row count (Example: if the total row count is 1000 -> categories that occur *50-100 times*)\n",
    "    * **Low frequency**: categories that occur less times than 5% of the total row count (Example: if the total row count is 1000 -> categories that occur *less than 50 times*)\n",
    "    * **Missing**: null occurencies (note: since there are a couple of categorical variables with significant percentages of null occurencies, we wanted to retain this information to see if it potentially creates some signal for our models)\n",
    "\n",
    "* Convert the categorical features to numerical using *One-hot Encoding* and the buckets obtained above. Specifically, we decided to keep all the one-hot encoded categories from the High Frequency bucket as separate columns, in order to obtain all signals from the categories that appear to be the most important for our classification problem. However, we decided to not discard the remaining categories/features, but instead add three additional columns one for each of the: Medium frequency, Low frequency and Missing buckets. If, for example, record X has any category that belongs to the Medium frequency bucket (based on the counts explained above), then the `Medium Frequency` column for that record will be `1`, otherwise it will be `0`. \n",
    "\n",
    "Below, we will demonstrate how the bucketing and one-hot encoding were applied in a scalable manner to our Criteo dataset, using our toy dataset with 1000 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**. Obtain the occurence counts for each category:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *part a:* Using variable `C1` as an example to demonstrate the implementation. The analysis above showed that variable `C1` has 57 uniques categories, hence we will obtain the occurence counts for each of the 57 categories in `C1`. Each of these categories will then be placed in one of the 4 buckets mentioned above based on its occurence counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('05db9164', 485),\n",
       " ('68fd1e64', 146),\n",
       " ('5a9ed9b0', 103),\n",
       " ('8cf07265', 51),\n",
       " ('be589b51', 41),\n",
       " ('5bfa8ab5', 27),\n",
       " ('f473b8dc', 20),\n",
       " ('87552397', 15),\n",
       " ('39af2607', 13),\n",
       " ('9a89b36c', 9)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C1 has var_position = 13\n",
    "category_counts_C1 = normedToyRDDCached.map(lambda x: ( x[0][13], 1)) \\\n",
    "                                       .reduceByKey(lambda x,y: x+y) \\\n",
    "                                       .sortBy(lambda x: -x[1])\n",
    "\n",
    "category_counts_C1.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *part b:* Apply the same logic on all variables using Spark's `flatMap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function \n",
    "def count_cat_count(line):\n",
    "    features, label = line[0], line[1]\n",
    "    result = []\n",
    "    for i in list(range(13,39)): \n",
    "        result.append((features[i], 1))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a73ee510', 900),\n",
       " ('25c83c98', 653),\n",
       " ('0b153874', 597),\n",
       " ('e5ba7672', 497),\n",
       " ('05db9164', 485),\n",
       " ('32c7478e', 447),\n",
       " ('7e0ccccf', 388),\n",
       " ('b28479f6', 367),\n",
       " ('21ddcdc9', 358),\n",
       " ('07d13a8f', 320)]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_counts_all = normedToyRDDCached.flatMap(count_cat_count) \\\n",
    "                                        .reduceByKey(lambda x,y: x+y) \\\n",
    "                                        .sortBy(lambda x: -x[1]) \\\n",
    "                                        .filter(lambda x: x[0] != 'null') \n",
    "category_counts_all.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**. Classify each category into one of the 4 buckets mentioned above based on its occurence counts and broadcast this information. As we learned throughout the semester, broadcasted variables are very useful in cases where the programmer wants to pass a copy of some useful information to every node in an efficient manner. \n",
    "\n",
    "* `>=` 100 times (i.e. 10% of 1000 rows) -> *High frequency* \n",
    "* 50-100 times (i.e. 5-10% of 1000 rows) -> *Medium frequency* \n",
    "* `<`50 times (i.e. 5% of 1000 rows) -> *Low frequency* \n",
    "* `==` 'null' -> *Missing*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying on C1 only \n",
    "high_frequency_categorices_C1 = sc.broadcast(category_counts_C1.filter(lambda x: x[1] >= 100) \\\n",
    "                                               .map(lambda x: x[0]).collect())\n",
    "medium_frequency_categorices_C1 = sc.broadcast(category_counts_C1.filter(lambda x: x[1] < 100 and x[1] >= 50) \\\n",
    "                                               .map(lambda x: x[0]).collect())\n",
    "low_frequency_categorices_C1 = sc.broadcast(category_counts_C1.filter(lambda x: x[1] < 50) \\\n",
    "                                               .map(lambda x: x[0]).collect())\n",
    "\n",
    "# applying to all variables  \n",
    "high_frequency_categorices = sc.broadcast(category_counts_all.filter(lambda x: x[1] >= 100) \\\n",
    "                                               .map(lambda x: x[0]).collect())\n",
    "medium_frequency_categorices = sc.broadcast(category_counts_all.filter(lambda x: x[1] < 100 and x[1] >= 50) \\\n",
    "                                               .map(lambda x: x[0]).collect())\n",
    "low_frequency_categorices = sc.broadcast(category_counts_all.filter(lambda x: x[1] < 50) \\\n",
    "                                               .map(lambda x: x[0]).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High frequency categories: ['05db9164', '68fd1e64', '5a9ed9b0'] \n",
      "\n",
      "Medium frequency categories: ['8cf07265'] \n",
      "\n",
      "Low frequency categories: ['be589b51', '5bfa8ab5', 'f473b8dc', '87552397', '39af2607', '9a89b36c', 'ae82ea21', '241546e0', '09ca0b81', '17f69355', '439a44a4', '1464facd', 'fb174e6b', 'b455c6d7', '75ac2fe6', '45cb84c9', '28e55712', '7e5c2ff4', 'd4b08d58', 'da4eff0f', 'c974c00b', '42a16b9a', '3b65d647', 'fbc55dae', 'b19f768d', '2ebc17d3', '37d3940e', '5ebc3192', '3c9d8785', '9684fd4d', 'a14cf13a', '49807078', 'dac91c28', '439f942d', '41edac3d', '813d7135', '06584483', '291b7ba2', '40e1377d', 'e8ef605b', '394fc830', 'eb6dcae0', 'bfb430af', '5d7d2fe8', 'c79f9af8', '88abfaf6', '426610d2', '18988050', '0a16e1d4', '92fb1d87', 'c71ae391', 'abca0bad', '46300ee3'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# C1 \n",
    "print('High frequency categories: {} \\n'.format(high_frequency_categorices_C1.value))\n",
    "print('Medium frequency categories: {} \\n'.format(medium_frequency_categorices_C1.value))\n",
    "print('Low frequency categories: {} \\n'.format(low_frequency_categorices_C1.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High frequency categories: ['a73ee510', '25c83c98', '0b153874', 'e5ba7672', '05db9164', '32c7478e', '7e0ccccf', 'b28479f6', '21ddcdc9', '07d13a8f', '3b08e48b', 'a458ea53', 'fbad5c96', '3a171ecb', 'b1252a9d', 'fe6b92e5', '5840adea', '4cf72387', '5b392875', '1adce6ef', '68fd1e64', 'ad3062eb', '001f3601', 'd4bb7bd8', '38a947a1', 'e8b83407', '423fab69', '07c540c4', '5a9ed9b0', '7cc72ec2'] \n",
      "\n",
      "Medium frequency categories: ['c9d4222a', 'ea9a246c', 'bcdee96c', '1f89b562', '3486227d', 'be7c41b4', '43b19349', '3fdb382b', '1e88c74f', '776ce399', '8cf07265', '1cfdf714', 'b34f3128'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All variables \n",
    "print('High frequency categories: {} \\n'.format(high_frequency_categorices.value))\n",
    "print('Medium frequency categories: {} \\n'.format(medium_frequency_categorices.value))\n",
    "# print('Low frequency categories: {} \\n'.format(low_frequency_categorices.value)) # this category is too large to print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.** Applying a homegrown one-hot encoding implementation as explained above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1 example: the new columns of our dataset now are\n",
    "FIELDS_NEW = ['I1','I2','I3','I4','I5','I6','I7','I8','I9','I10','I11','I12','I13', # numerical \n",
    "          '05db9164','68fd1e64','5a9ed9b0','Medium_Freq','Low_Freq','Missing',      # categorical \n",
    "          'Label']                                                                  \n",
    "\n",
    "# all variables: the new columns of our dataset now are\n",
    "FIELDS_NEW = ['I1','I2','I3','I4','I5','I6','I7','I8','I9','I10','I11','I12','I13',                                    # numerical \n",
    "          'high freq feature 1','high freq feature 2'...'high freq feature n','Medium_Freq','Low_Freq','Missing',      # categorical \n",
    "          'Label']                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OHE_transform(line):\n",
    "    \"\"\"\n",
    "    One hot encoding transformation of an RDD \n",
    "    using the high/medium/low/missing logic\n",
    "    \n",
    "    returns: (ohe_transformed_features, label)\n",
    "    \"\"\"\n",
    "    features, label = line[0], line[1]\n",
    "    cat_features = []\n",
    "    num_features = []\n",
    "    for i, value in enumerate(features):\n",
    "        if i > 12 and i < 39: \n",
    "            cat_features.append(value)\n",
    "        else:\n",
    "            num_features.append(value)\n",
    "\n",
    "    high_freq_list = [1 if i in cat_features else 0 for i in high_frequency_categorices.value]\n",
    "    medium_freq = 1 if any(i in cat_features for i in medium_frequency_categorices.value) else 0\n",
    "    low_freq = 1 if any(i in cat_features for i in low_frequency_categorices.value) else 0\n",
    "    missing = 1 if any(i in cat_features for i in ['null']) else 0\n",
    "    ohe_features = high_freq_list + [medium_freq] + [low_freq] + [missing]\n",
    "\n",
    "    return (num_features + ohe_features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "oheTrasformedToyRDDCached = normedToyRDDCached.map(OHE_transform).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([-0.5433608510385987, 0.8580968676474047, -0.12839483402657934, 0.0, -0.21404880541365456, 0.3873814615646774, -0.07403520683960009, 0.002878252461803471, 1.0729765767787602, -0.9112734540131763, 0.8646834019878579, 0.0, 0.0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1], 1)]\n"
     ]
    }
   ],
   "source": [
    "print(oheTrasformedToyRDDCached.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Algorithm Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Application of Course Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
