{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W261 Final Project\n",
    "\n",
    "#### *Anusha Munjuluri, Arvindh Ganesan, Kim Vignola, Christina Papadimitriou*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import yaml\n",
    "# import pydot\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from math import sqrt\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "from random import seed, randrange\n",
    "from collections import defaultdict\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "# Imports for DF and MLIB\n",
    "from pyspark.sql import types\n",
    "import pyspark.sql\n",
    "import pyspark.sql.functions\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.functions import col, countDistinct, approxCountDistinct, count, when, desc\n",
    "from pyspark.ml.feature import QuantileDiscretizer, Bucketizer\n",
    "from pyspark.sql import DataFrameStatFunctions as statFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store path to notebook\n",
    "PWD = !pwd\n",
    "PWD = PWD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"final_project\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Question Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Background \n",
    "\n",
    "The following analysis is based on a Kaggle dataset from Criteo, an internet advertising company focused on retargeting. Criteo's goal is to increase online clickthrough rates among consumers who have previously visited an advertiser's website. This information will be used by Criteo to more efficiently provide the right ads to the right people. Optimizing the retargeting process not only helps advertisers become more efficient in terms of how they spend their dollars, but also it reduces clutter for consumers who do not want to be \"followed\" by ads for irrelevant products (or ones they may have already purchased!). **Our goal is to create a model that will most accurately predict clickthroughs (label = 1); Due to binary categorical nature of the output label (0,1), we are exploring classification models for analysis.** \n",
    "\n",
    "Features given in the data set most likely represent characterstics about consumer behavior (history of clickthroughs, site visitiation, etc.), the ads themselves (product, creative approach, placement, etc.) and general metrics such as the date the ad was published.  However **since there is no visibility into what each feature represents, our challenge is to make our predictions based on the data alone. With over 6 million records to train each day (~45 million per week), this will require a scalable approach**.\n",
    "\n",
    "\n",
    "### Dataset Introduction \n",
    "\n",
    "The training dataset consists of a portion of Criteo's traffic over a period of 7 days. Each row corresponds to a display ad served by Criteo and the first column indicates whether this ad has been clicked or not. The positive (clicked) and negatives (non-clicked) examples have both been subsampled (but at different rates 75% - 0 Class, 25% - Class) in order to reduce the dataset size.\n",
    "\n",
    "**There are 13 numerical features (mostly count features) and 26 categorical features in this dataset. The values of the categorical features have been hashed onto 32 bits for anonymization purposes. The semantic of these features is undisclosed**. Some features may have missing values. All the rows are chronologically ordered. The test set is computed in the same way as the training set but it corresponds to events on the day following the training period and does not have the label column. Since, there is no time data available, we are not considering this dataset to be a time series model.\n",
    "\n",
    "\n",
    "### Key Questions: Features and Model\n",
    "\n",
    "#### 1. Which features are most important in predicting clickthroughs?\n",
    "\n",
    "Having this information can help Criteo focus on the metrics that are most critical to their product. With 39 features, there is a high risk of overfitting. We should identify a model that provides an optimal tradeoff between bias and variance. **Since we didnt get any metadata about the features, we are relying on EDA and regularization techniques to help us determine the important features and reduce dimensionality of the feature space**.\n",
    "\n",
    "\n",
    "#### 2. Which machine learning approach not only provides the highest accuracy in predicting clickthroughs, but is also scalable enough to be useful in a production environment?\n",
    "\n",
    "As internet patterns and product choices change rapidly, the ideal model should be trained daily to update the following day's retargeting model. Scaling would help us achieve shorter training times than processing records sequentially. **Any ML algorithm which can be trained using associative and commutative properties (ex. simple addition, with no state dependencies) such as Batch Logisitc Regression or Tree Algorithms based can be used for scaling the training approach.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA & Discussion of Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals for this section:\n",
    "\n",
    "#### PART A: Loading and Creating files with pre-processing \n",
    "\n",
    "1. Create RDDs for full train and test files. \n",
    "2. Sample full train RDD to create trainRDD for training, heldOutRDD for testing and a random sample of 1000 rows as toy dataset for demonstration purpose ('toy1000.txt').\n",
    "3. Take another random sample of 300 rows from the train file ('toy_test300.txt') which will be used to validate ML models in later sections. \n",
    "\n",
    "#### PART B: EDA with Toy Dataset and RDDs/Pandas\n",
    "\n",
    "Perform EDA on toy dataset using pandas/RDDs including visualizations that help inform our data transformation decisions.  \n",
    "\n",
    "#### PART C:  EDA on Full Dataset with Dataframes \n",
    "\n",
    "Perform EDA on full train dataset using Dataframes.\n",
    "\n",
    "#### PART D: Data Transformation on Toy Dataset\n",
    "Data transformations using Spark RDDs on toy dataset.  \n",
    "\n",
    "**NOTE: In section 4, we perform the same data transformations on entire dataset using Spark Dataframes for Spark ML models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART A: LOADING AND CREATING FILES WITH PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files and Columns Details:\n",
    "\n",
    "1. **Full Train File 'train.txt'**:  Number of rows: 45840617 (~ 45 million; ~ 10 GB) 40 columns\n",
    "2. **Full Test File 'test.txt'**: Number of rows: 6042135 (~ 6 million; 1.4 GB) 39 columns (all columns except label column)\n",
    "3. **Toy Train File 'toy100.txt'**: A random sample of 1000 rows as toy dataset for demonstration purpose with the same number of columns as the train file. \n",
    "4. **Toy Test File 'toy_test300.txt'**: A random sample of 300 rows as toy test dataset with the same of columns as the train file and validation of ML models in later section. \n",
    "4. **Columns**: 40\n",
    "    -  13 Numerical Features I1-I13\n",
    "    -  26 Categorical Features C1-C26\n",
    "    -  1 Label Column - 0 or 1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t1\t1\t5\t0\t1382\t4\t15\t2\t181\t1\t2\t\t2\t68fd1e64\t80e26c9b\tfb936136\t7b4723c4\t25c83c98\t7e0ccccf\tde7995b8\t1f89b562\ta73ee510\ta8cd5504\tb2cb9c98\t37c9c164\t2824a5f6\t1adce6ef\t8ba8b39a\t891b62e7\te5ba7672\tf54016b9\t21ddcdc9\tb1252a9d\t07b5194c\t\t3a171ecb\tc5c50484\te8b83407\t9727dd16\n"
     ]
    }
   ],
   "source": [
    "# take a look at the full train file data top row \n",
    "!head -n 1 data/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the full train and test files\n",
    "fullTrainRDD = sc.textFile('data/train.txt')\n",
    "testRDD = sc.textFile('data/test.txt')\n",
    "\n",
    "FIELDS = ['I1','I2','I3','I4','I5','I6','I7','I8','I9','I10','I11','I12','I13',\n",
    "          'C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14',\n",
    "          'C15','C16','C17','C18','C19','C20','C21','C22','C23','C24','C25','C26','Label']\n",
    "\n",
    "# Get categorical and numeric field names separately\n",
    "NUM_FIELDS = FIELDS[0:13]\n",
    "CAT_FIELDS = list(set(FIELDS)-set(NUM_FIELDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in train data: 45840617 ...\n",
      "Number of records in test data: 6042135 ...\n"
     ]
    }
   ],
   "source": [
    "# number of rows in full train/test data\n",
    "print(f\"Number of records in train data: {fullTrainRDD.count()} ...\")\n",
    "print(f\"Number of records in test data: {testRDD.count()} ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creating Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... held out 9167871 records for evaluation and assigned 36672746 for training.\n"
     ]
    }
   ],
   "source": [
    "# Generate 80/20 (pseudo)random train/test split \n",
    "trainRDD, heldOutRDD = fullTrainRDD.randomSplit([0.8,0.2], seed = 1)\n",
    "print(f\"... held out {heldOutRDD.count()} records for evaluation and assigned {trainRDD.count()} for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Creating a toy RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Toy Train Set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A train toy data set was created by randomly sampling 1000 records from the dataset: \n",
    "\n",
    "`!gshuf -n 1000 data/train.txt >> data/toy1000.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in toy data: 1000 ...\n"
     ]
    }
   ],
   "source": [
    "toyRDD = sc.textFile('data/toy1000.txt')\n",
    "print(f\"Number of records in toy data: {toyRDD.count()} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1\\t0\\t478\\t13\\t\\t3396\\t194\\t11\\t13\\t312\\t0\\t7\\t\\t\\t05db9164\\t207b2d81\\t1757640a\\t06148e59\\t25c83c98\\tfbad5c96\\tf36791d8\\t0b153874\\ta73ee510\\tc7009b63\\t2714650d\\t1a69f1c0\\t9a88e2e2\\t07d13a8f\\t0c67c4ca\\t8075af0c\\te5ba7672\\t395856b0\\t21ddcdc9\\tb1252a9d\\t8e4884c0\\t\\t423fab69\\tb936bfbe\\t001f3601\\tf2fc1d6e']\n"
     ]
    }
   ],
   "source": [
    "print(toyRDD.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Toy Test Set \n",
    "\n",
    "We will randomly sample a toy held-out dataset frim the `train.txt` file.\n",
    "\n",
    "`!gshuf -n 300 data/train.txt >> data/toy_test300.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toy_testRDD = sc.textFile('data/toy_test300.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def parse(line):\n",
    "    \"\"\"\n",
    "    Map line --> tuple of (features, label)\n",
    "    \"\"\"\n",
    "    fields = line.split('\\t')\n",
    "    features,label = fields[1:], fields[0]\n",
    "    return(features, label)\n",
    "\n",
    "def edit_data_types(line):\n",
    "    \"\"\"\n",
    "    Map tuple of (features, label) --> tuple of (formated features, label)\n",
    "    \n",
    "    * '' is replaced with 'null'\n",
    "    * numerical fields are converted to integers\n",
    "    * make label column numeric\n",
    "    \"\"\"\n",
    "    features, label = line[0], line[1]\n",
    "    formated_features = []\n",
    "    for i, value in enumerate(features):\n",
    "        if value == '':\n",
    "            formated_features.append('null')\n",
    "        else:\n",
    "            if i < 13:\n",
    "                formated_features.append(float(value)) \n",
    "            else:\n",
    "                formated_features.append(value)\n",
    "    return (formated_features, int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parsing, making '' as np.nan and converting numerical features and output label to int\n",
    "trainRDDCached = trainRDD.map(parse).map(edit_data_types).cache()\n",
    "toyRDDCached = toyRDD.map(parse).map(edit_data_types).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([1.0, 1.0, 5.0, 0.0, 1382.0, 4.0, 15.0, 2.0, 181.0, 1.0, 2.0, 'null', 2.0, '68fd1e64', '80e26c9b', 'fb936136', '7b4723c4', '25c83c98', '7e0ccccf', 'de7995b8', '1f89b562', 'a73ee510', 'a8cd5504', 'b2cb9c98', '37c9c164', '2824a5f6', '1adce6ef', '8ba8b39a', '891b62e7', 'e5ba7672', 'f54016b9', '21ddcdc9', 'b1252a9d', '07b5194c', 'null', '3a171ecb', 'c5c50484', 'e8b83407', '9727dd16'], 0)]\n"
     ]
    }
   ],
   "source": [
    "print(trainRDDCached.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([0.0, 478.0, 13.0, 'null', 3396.0, 194.0, 11.0, 13.0, 312.0, 0.0, 7.0, 'null', 'null', '05db9164', '207b2d81', '1757640a', '06148e59', '25c83c98', 'fbad5c96', 'f36791d8', '0b153874', 'a73ee510', 'c7009b63', '2714650d', '1a69f1c0', '9a88e2e2', '07d13a8f', '0c67c4ca', '8075af0c', 'e5ba7672', '395856b0', '21ddcdc9', 'b1252a9d', '8e4884c0', 'null', '423fab69', 'b936bfbe', '001f3601', 'f2fc1d6e'], 1)]\n"
     ]
    }
   ],
   "source": [
    "print(toyRDDCached.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Some extra pre-processing for a pandas DataFrame for EDA use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function 'null' to np.nan for pandas df \n",
    "def null_to_nan(line):\n",
    "    \"\"\"\n",
    "    converts \"null\" to np.nan in RDD\n",
    "    \"\"\"\n",
    "    features, label = line[0], line[1]\n",
    "    formated_features = []\n",
    "    for i, value in enumerate(features):\n",
    "        if value == 'null':\n",
    "            formated_features.append(np.nan)\n",
    "        else:\n",
    "            formated_features.append(value)\n",
    "    return (formated_features, label)\n",
    "\n",
    "# put the toy RDD into a pandas dataframe for EDA charting\n",
    "toyRDDtoPandas = toyRDDCached.map(null_to_nan) \\\n",
    "                                .map(lambda x: np.append(x[0], [x[1]])) \\\n",
    "                                .collect()\n",
    "\n",
    "toy_df = pd.DataFrame(toyRDDtoPandas, columns=FIELDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>...</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>3396.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>395856b0</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>8e4884c0</td>\n",
       "      <td>nan</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>b936bfbe</td>\n",
       "      <td>001f3601</td>\n",
       "      <td>f2fc1d6e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>526e8765</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>8b7fb864</td>\n",
       "      <td>nan</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>45b2acf4</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>8f9b4e88</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>050a23dc</td>\n",
       "      <td>nan</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>8a3cfad4</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2804effd</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>723b4dfd</td>\n",
       "      <td>nan</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>b34f3128</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e88ffc9d</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>dca9a28d</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>3fdb382b</td>\n",
       "      <td>cb079c2d</td>\n",
       "      <td>1c2df582</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    I1     I2    I3    I4      I5     I6    I7    I8     I9  I10  ...   \\\n",
       "0  0.0  478.0  13.0   nan  3396.0  194.0  11.0  13.0  312.0  0.0  ...    \n",
       "1  2.0    0.0   nan   nan  1209.0    0.0   2.0   1.0    0.0  1.0  ...    \n",
       "2  nan    1.0   1.0   8.0   489.0   66.0   0.0  11.0    8.0  nan  ...    \n",
       "3  0.0  179.0   7.0   8.0   996.0   67.0   6.0  44.0  344.0  0.0  ...    \n",
       "4  2.0    2.0  10.0  27.0  1101.0   29.0  11.0  42.0  241.0  1.0  ...    \n",
       "\n",
       "        C18       C19       C20       C21       C22       C23       C24  \\\n",
       "0  395856b0  21ddcdc9  b1252a9d  8e4884c0       nan  423fab69  b936bfbe   \n",
       "1  526e8765       nan       nan  8b7fb864       nan  32c7478e  45b2acf4   \n",
       "2  8f9b4e88       nan       nan  050a23dc       nan  32c7478e  8a3cfad4   \n",
       "3  2804effd       nan       nan  723b4dfd       nan  32c7478e  b34f3128   \n",
       "4  e88ffc9d  21ddcdc9  b1252a9d  dca9a28d  ad3062eb  bcdee96c  3fdb382b   \n",
       "\n",
       "        C25       C26 Label  \n",
       "0  001f3601  f2fc1d6e     1  \n",
       "1       nan       nan     0  \n",
       "2       nan       nan     0  \n",
       "3       nan       nan     0  \n",
       "4  cb079c2d  1c2df582     1  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART B: EDA WITH TOY DATASET USING RDDs/PANDAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we take a look at the percentage of records that belong to each label for our classification problem in order to determine whether our classes are balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.3 % of the records have label=0 and 27.7 % have label=1...\n"
     ]
    }
   ],
   "source": [
    "# TOY DATA\n",
    "# counting records for each class \n",
    "count_label_0 = toyRDDCached.filter(lambda x: x[1] == 0).count()\n",
    "count_label_1 = toyRDDCached.filter(lambda x: x[1] == 1).count()\n",
    "total = count_label_0 + count_label_1\n",
    "\n",
    "print(f\"{np.round(count_label_0/total*100, 2)} % of the records have label=0 and {np.round(count_label_1/total*100, 2)} % have label=1...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5ac0896d616b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# FULL DATA  ( Don't re-run this!!! )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# counting records for each class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcount_label_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainRDDCached\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcount_label_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainRDDCached\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_label_0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcount_label_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \"\"\"\n\u001b[0;32m-> 1073\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;36m6.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \"\"\"\n\u001b[0;32m-> 1064\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\u001b[0m in \u001b[0;36mfold\u001b[0;34m(self, zeroValue, op)\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0;31m# zeroValue provided to each partition is unique from the one provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;31m# to the final reduce call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeroValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m         \"\"\"\n\u001b[1;32m    833\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# FULL DATA  ( Don't re-run this!!! )\n",
    "# counting records for each class \n",
    "count_label_0 = trainRDDCached.filter(lambda x: x[1] == 0).count()\n",
    "count_label_1 = trainRDDCached.filter(lambda x: x[1] == 1).count()\n",
    "total = count_label_0 + count_label_1\n",
    "\n",
    "print(f\"{np.round(count_label_0/total*100, 2)} % of the records have label=0 and {np.round(count_label_1/total*100, 2)} % have label=1...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result above show that the **labels are imbalanced**, with 75% of records having label=0 (i.e. unclicked ads). However, we will not attempt to balance the labels at this stage. **Being aware of this imbalance, we will carefully examine the prediction results to detect any model bias (i.e. predicting always label=0)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Counting nulls in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we take a look at the percentage of null values for all columns in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pct_nulls_in_column(dataRDD, var_position):\n",
    "    \"\"\"\n",
    "    Counts the % nulls in a column \n",
    "    \"\"\"\n",
    "\n",
    "    null_count = dataRDD.map(lambda x: x[0][var_position]) \\\n",
    "                             .filter(lambda x: x == 'null').count()\n",
    "    total_count = dataRDD.map(lambda x: x[0][var_position]).count()\n",
    "\n",
    "    return null_count/total_count*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOY DATA\n",
    "for var_position, var in enumerate(FIELDS):\n",
    "\n",
    "    if var_position < 39:\n",
    "        null_pct = get_pct_nulls_in_column(toyRDDCached, var_position)\n",
    "        print(\"FEATURE {}: {}% is null\".format(var, np.round(null_pct,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that some columns have a high % of null values. **We could exclude columns that have more than 50% nulls when calculated on full train dataset because those columns will likely not contribute a lot to the prediction results. However, since those variables with more than 50% missing values are categorical variables, the one-hot encoding approach that we will take later on will take care of this issue**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Numeric Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7.1 Get Summary Statistics and Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we take a look at the summary statistics for our numerical features in order to determine their distributions and detect outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RDD version \n",
    "def get_stats(dataRDD, var_position):\n",
    "    \"\"\"\n",
    "    Get statistics for numeric variables \n",
    "    stats: mean, median, variance, min, max \n",
    "    \"\"\"\n",
    "\n",
    "    mean = dataRDD.map(lambda x: x[0][var_position]).filter(lambda x: x != 'null').mean() \n",
    "    variance = dataRDD.map(lambda x: x[0][var_position]).filter(lambda x: x != 'null').variance() \n",
    "    minimum = dataRDD.map(lambda x: x[0][var_position]).filter(lambda x: x != 'null').min() \n",
    "    maximum = dataRDD.map(lambda x: x[0][var_position]).filter(lambda x: x != 'null').max() \n",
    "\n",
    "    return mean, variance, minimum, maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the means in a dictionary\n",
    "mean_dict_toy = {}\n",
    "st_dev_dict_toy = {}\n",
    "\n",
    "# get summary stats with RDDs\n",
    "for var_position, var in enumerate(FIELDS):\n",
    "    if var_position < 13:\n",
    "        mean, variance, minimum, maximum = get_stats(toyRDDCached, var_position)\n",
    "        print(\"FEATURE {}: \\t mean={}, \\t variance={}, \\t min={}, \\t max={}\".format(var, np.round(mean, 2), np.round(variance, 2), minimum, maximum))\n",
    "        mean_dict_toy[var_position] = mean\n",
    "        st_dev_dict_toy[var_position] = np.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas version \n",
    "num_columns = ['I1','I2','I3','I4','I5','I6','I7','I8','I9','I10','I11','I12','I13']\n",
    "toy_df_num = toy_df[num_columns].astype(np.float)\n",
    "toy_df_num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at histograms for each numeric feature \n",
    "toy_df_num.hist(figsize=(20,15), bins=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot boxplots of each feature vs. the outcome\n",
    "fig, ax_grid = plt.subplots(5, 3, figsize=(20,15))\n",
    "y = toy_df['Label']\n",
    "for idx, feature in enumerate(num_columns):\n",
    "    x = toy_df_num[feature]\n",
    "    sns.boxplot(x, y, ax=ax_grid[idx//3][idx%3], orient='h', linewidth=.5)\n",
    "    ax_grid[idx//3][idx%3].invert_yaxis()\n",
    "fig.suptitle(\"BoxPlots by Label\", fontsize=15, y=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above results show that most of the numeric features are heavily skewed with several outliers on the right end. Hence, we decided to impute the missing values in the numeric features with median value for each corresponding column than mean as mean will be skewed due to the large number of outliers.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7.2 Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between numerical features\n",
    "corr = toy_df_num.corr()\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "cmap = sns.diverging_palette(10, 240, as_cmap=False)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, center=0, linewidths=.2)\n",
    "plt.title(\"Correlations between features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We observe that some of the numerical variables are highly correlated with each other. In the context of Logistic Regression we would want to eliminate features that are highly correlated with each other. A regularization  technique like Lasso or Ridge could take care of this. However, since Logistic regression is just our baseline model and we are focusing on tree-based algorithms, we do not need to worry about this. Tree-based models know how to assign variable importance and do not require any significant feature engineering.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will perform data processing on the 26 categorical features of the dataset. We will start by performing some EDA to compute the **number of unique categories** within each categorical feature and the total counts for each category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_categories(dataRDD, var, var_position, top):\n",
    "    \"\"\"\n",
    "    input: RDD, name and position of a categorical variable \n",
    "    \n",
    "    output: \n",
    "    * number of unique categories in the variable\n",
    "    * counts of each category occurance by label\n",
    "    \"\"\"\n",
    "    \n",
    "    # counting category occurance within each categorical feature \n",
    "    count_per_category = dataRDD.map(lambda x: ( x[0][var_position], 1)) \\\n",
    "                                           .reduceByKey(lambda x,y: x+y) \\\n",
    "                                           .sortBy(lambda x: -x[1])\n",
    "\n",
    "    # counting number of unique values within the categorical variable\n",
    "    num_unique_values = count_per_category.map(lambda x: x[0]).distinct().count()\n",
    "\n",
    "    print('Unique values within the category:', num_unique_values)\n",
    "    print(' ')\n",
    "    top_x = count_per_category.take(top)\n",
    "    print('Top {} categories by count:'.format(top))\n",
    "    for i in top_x: \n",
    "        print('Category: {}; Count: {}'.format(i[0],i[1]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TOY DATA\n",
    "for var_position, var in enumerate(FIELDS):\n",
    "\n",
    "    if var_position > 12 and var_position < 39:\n",
    "        print(\" \")\n",
    "        print(\"VARIABLE {}\".format(var))\n",
    "        print(\" \")\n",
    "        count_categories(toyRDDCached, var, var_position=var_position, top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bar graphs of category counts within each categorical variable by label\n",
    "fig, ax = plt.subplots(13, 2,figsize=(15,40))\n",
    "plt.tight_layout()\n",
    "fno = 0\n",
    "# axes are in a two-dimensional array, indexed by [row, col]\n",
    "for i in range(13):\n",
    "    for j in range(2):\n",
    "        fno += 1\n",
    "        col = \"C\" + str(fno)\n",
    "        sns.countplot(y=col, hue=\"Label\", data=toy_df, palette=\"Greens_d\",\n",
    "                  order=toy_df[col].value_counts().iloc[:10].index,ax=ax[i,j]).set_title('Count By C'+str(fno)+' Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above analysis shows that some categorical variables have a high number of unique categories. Aditionally, the distribution of counts for most of the categorical variables is very skewed (i.e. some categories appear much more often than others). Considering this information, we decided to bucket the categorical features into 'High', 'Medium', 'Rare' and 'Missing' buckets for each column which will be explained later in the data transformation section.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART C:  EDA ON FULL DATASET USING DATAFRAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Creating a dataframe for TrainRDD (from above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampleDF = trainRDDCached.map(lambda x: np.append(x[0], [x[1]])).map(lambda x: x.tolist()).toDF(FIELDS).cache()\n",
    "                                                                   \n",
    "# Converting Columns to Numeric Type\n",
    "for col_name in NUM_FIELDS:\n",
    "    sampleDF = sampleDF.withColumn(col_name, col(col_name).cast('float'))\n",
    "sampleDF = sampleDF.withColumn(\"Label\", col(\"Label\").cast('int')).cache()\n",
    "\n",
    "# Show col types and top row\n",
    "start = time.time()\n",
    "sampleDF.head(1)\n",
    "print(f'\\n... {time.time() - start} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 Categorical Features: \n",
    "\n",
    "* Get missing fields, distinct features count and high/medium frequency features for categorical columns. \n",
    "\n",
    "\n",
    "* **Each categorical column has a large number of distinct features and missing values (ex. 'C22') which makes categorical columns One Hot Encoding cumbersome** and increases the dimensionality of the feature space by several times. This will make the ML models perform not very well if these categorical columns are used as is. Hence, **as a bucketing technique we are getting the list of features by their counts to group them as 'High', 'Medium', 'Rare' or 'Missing'**. \n",
    "\n",
    "    * **High Frequency Features:** are those which which occur at least 10% of the time. Ex: if n = 45 million; 10% of n = 4.5million. ie. give me a list of categorical features (categories) in a column that occur at least 10% of the time. \n",
    "\n",
    "    * **Medium Frequency Features:** Categories that occur 2%-10% of the time in a column\n",
    "\n",
    "    * **Rare Features**: After getting the 'High' and 'Medium' frequency features from a column, remaining features would all be clubbed under the 'Rare' category which occur less than 2% of the time \n",
    "    \n",
    "    * **Missing**: If they are nulls, they are bucketed as 'Missing'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Keep a dictionary of high and low features\n",
    "high_features = dict()\n",
    "medium_features =  dict()\n",
    "\n",
    "# total row count\n",
    "row_count = sampleDF.count()\n",
    "\n",
    "for field in CAT_FIELDS:\n",
    "    print(\"\\nFOR COLUMN \"+field+\":\")\n",
    "    \n",
    "    columnDF = sampleDF[[field]].cache()\n",
    "    \n",
    "    #Count of missing \n",
    "    missing_count = columnDF.select(count(when(col(field) == \"null\", 1))).head()[0]\n",
    "    print(\"No. of Missing Values:\", missing_count)\n",
    "    \n",
    "    print(\"Percentage of Missing values:\", round(missing_count*100/row_count, 2), \"%\")\n",
    "    \n",
    "    # Distinct\n",
    "    distinct = columnDF.agg(approxCountDistinct(col(field)).alias(field)).head()[0]\n",
    "    if missing_count != 0:\n",
    "        distinct = distinct -1\n",
    "    print(\"No. of Distinct Features (without null):\", distinct)\n",
    "    \n",
    "    # Frequent Items \n",
    "    freq10 = columnDF.stat.freqItems([field], 0.1).head()[0]\n",
    "    freq2 = columnDF.stat.freqItems([field], 0.02).head()[0]\n",
    "    freq2 = list(set(freq2) - set(freq10))\n",
    "    print(\"10% Occuring Features:\", freq10)\n",
    "    print(\"2% Occuring Features:\", freq2)\n",
    "    \n",
    "    high_features[field] = freq10\n",
    "    medium_features[field] =  freq2\n",
    "\n",
    "print(f'\\n... {time.time() - start} seconds.')   \n",
    "\n",
    "# writing list of features to pickle files for future reference \n",
    "with open(r\"highfeatures.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(high_features, output_file)\n",
    "with open(r\"mediumfeatures.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(medium_features, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.11 Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.11.1 Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get numeric features summary stats\n",
    "start = time.time()\n",
    "numeric_summaryDF = sampleDF[[NUM_FIELDS]].summary().cache()\n",
    "\n",
    "# Round numeric summary stats\n",
    "for field in NUM_FIELDS:\n",
    "    numeric_summaryDF = numeric_summaryDF.withColumn(field, func.round(numeric_summaryDF[field], 2))\n",
    "    split = set([value[0] for value in numeric_summaryDF[[field]].collect()[3:]])\n",
    "    splits.append(sorted(list(split)))\n",
    "\n",
    "# Display numeric summary stats\n",
    "numeric_summaryDF.show()\n",
    "\n",
    "print(f'\\n... {time.time() - start} seconds.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I12 is one of the columns that has the most missing values (> 50%). Missing values are being imputed with medians as discussed in the next sections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.11.2 Column Quantiles to bucket numeric features\n",
    "\n",
    "Note: values are [min, 25%, median, 75%, max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splits = []\n",
    "start = time.time()\n",
    "\n",
    "# Round numeric summary stats\n",
    "for field in NUM_FIELDS:\n",
    "    split = set(statFunc(sampleDF).approxQuantile(field, probabilities = [0.0,0.25,0.50,0.75,1.0], relativeError=0.2))\n",
    "    splits.append(sorted(list(split)))\n",
    "\n",
    "print(\"COLUMN QUANTILES (keeping only unique values for binning):\\n\")\n",
    "print(splits)\n",
    "\n",
    "print(f'\\n... {time.time() - start} seconds.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.11.3 Bucket each numerical column based on quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_buckets = []\n",
    "buckets = []\n",
    "start = time.time()\n",
    "\n",
    "for i,field in enumerate(NUM_FIELDS):\n",
    "    if len(splits[i])==2:\n",
    "        splits[i] = [-float(\"inf\")] + splits[i] + [float(\"inf\")]\n",
    "        \n",
    "    # Bucketize the values\n",
    "    bucketizer = Bucketizer(handleInvalid = 'skip', splits = splits[i], inputCol=field, outputCol=\"bucket\")\n",
    "    result = bucketizer.transform(sampleDF[[field]]).cache()\n",
    "    print(\"\\nFOR COLUMN \"+field+\":\", \"splits are:\", splits[i])\n",
    "    \n",
    "    # Get ccount of each bucket in a column\n",
    "    bucket = result.groupBy([\"bucket\"]).agg(count(\"bucket\").alias(\"count\")).orderBy(\"bucket\")\n",
    "    count_buckets.append([value[1] for value in bucket.collect()])\n",
    "    buckets.append([value[0] for value in bucket.collect()])\n",
    "    print(bucket.show())\n",
    "    \n",
    "print(\"Buckets:\", buckets)\n",
    "print(\"Bucket Counts:\", count_buckets)\n",
    "\n",
    "print(f'\\n... {time.time() - start} seconds.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.11.4 Visualize each of the bucketed numerical column \n",
    "\n",
    "Note: if values are too low, they are not shown in the plot. Look at count values in title to determine which buckets are a minority/outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for j, field in enumerate(NUM_FIELDS):\n",
    "    N = len(buckets[j])\n",
    "    index = np.arange(N)\n",
    "    bar_width = 0.95\n",
    "    labels = []\n",
    "\n",
    "    for i in range(N):\n",
    "        labels.append(str(splits[j][i]) + \"-\" + str(splits[j][i+1]))\n",
    "\n",
    "    plt.bar(buckets[j], count_buckets[j], align='center', alpha=0.5)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(index, labels)   \n",
    "    plt.title('Bar Plot Column: ' + field + '\\n'+str(count_buckets[j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Above plots show that most of the numeric features have outliers beyond the 75% percentile value on the right end but their count is much smaller compared to the other buckets.** \n",
    "\n",
    "\n",
    "* **There are not too many outliers for the Logistic Regression model estimates to be skewed by these values (relying on large sample asymptotics and invoking Central Limit Theorem!) and Decision Trees can anyways innately handle features with outliers.** Hence, we decided not to do any processing such as removing these outliers and retained them as is.  \n",
    "\n",
    "* However, to be on the safe side we decided to use median (as mean will be skewed because of the outliers) for imputing the values and standardize the features by computing mean post imputation, as means calculated before imputation would be skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.12 Label Column: Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label Column Distribution \n",
    "start = time.time()\n",
    "label1_count = sampleDF[['Label']].select(count(when(col('Label') == \"1\", 1))).head()[0]\n",
    "label0_count = sampleDF[['Label']].select(count(when(col('Label') == \"0\", 1))).head()[0]\n",
    "print(\"Number of rows with label = 1:\", label1_count , '\\n% of rows with label = 1:', round(label1_count*100/row_count,2), \"%\")\n",
    "print(\"\\nNumber of rows with label = 0:\", label0_count , '\\n% of rows with label = 0:', round(label0_count*100/row_count,2), \"%\")\n",
    "\n",
    "print('\\n...', time.time()-start, 'seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.13 Data Transformation Steps based on EDA  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our EDA on full train dataset, we decided to do the following transformations on columns:\n",
    "\n",
    "#### A. Numerical Columns:\n",
    "\n",
    " **1. Imputing with medians**: \n",
    "    \n",
    " We decided to impute the missing values in the numeric features with the median value for each corresponding column. **The choice of median instead of mean is made due to the multiple large outliers on the high end that would have caused our mean values to be larger (skewed).** Note, that there is no need to impute the null values for the categorical features since one hot encoding will take care of the nulls later on. \n",
    "    \n",
    "**2. Standardizing**: \n",
    "    \n",
    "In the summary statistics, **we noticed that the numerical features have different ranges for each column, and thus we decided to standardize our data** (i.e. subtracting by mean and dividing by standard deviation of each column), in order to scale them. **Standardization would also help with our Logistic Regression algorithm to coverge faster and use regularization to determine importance of coefficients**.\n",
    "\n",
    "#### B. Categorical Columns:\n",
    "\n",
    "**1. Bucketing as 'High', 'Medium', 'Rare', 'Missing':**\n",
    "\n",
    "The above analysis shows that some categorical variables have a high number of unique categories. Aditionally, the distribution of counts for most of the categorical variables is very skewed (i.e. some categories appear much more often than others). Considering this information, we decided to take the following approach to deal with categorical variables: \n",
    "\n",
    "Bucket the categories within each categorical column into 4 groups based on their occurence counts:\n",
    "\n",
    "    * **High frequency**: categories that occur more times than 10% of the total row count (Example: if the total row count is 1000 -> categories that occur *more than 100 times*)\n",
    "    * **Medium frequency**: categories that occur more times than 2% and less than 10% of the total row count (Example: if the total row count is 1000 -> categories that occur *50-100 times*)\n",
    "    * **Low frequency**: categories that occur less times than 2% of the total row count (Example: if the total row count is 1000 -> categories that occur *less than 50 times*)\n",
    "    * **Missing**: null occurencies (note: since there are a couple of categorical variables with significant percentages of null occurencies, we wanted to retain this information to see if it potentially creates some signal for our models)\n",
    "\n",
    "**2. One Hot Encoding:**\n",
    "\n",
    "Convert categorical features to numerical using *One-hot Encoding* as per the buckets obtained above for each column. Specifically, each categorical feature will be converted into 4 columns (`high`, `medium`, `low` and `missing`) that will have values of `1`'s and `0`'s denoting whether that record has a value for that categorical variable that belongs in one of the 4 buckets. This is an alternative data transformation method of categorical variables to numerical, instead of the traditional one-hot enconding. The choice for this method is based on the effort to retain all the information/signals from the categorical variables and at the same time reduce the dimensionality of the dataset compared to a traditional one-hot enconding transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART D: DATA TRANSFORMATION ON TOY DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.13.1 Impute nulls with medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute_nulls(line, mean_or_median_dict):\n",
    "    \"\"\"\n",
    "    Impute the null values of the numerical columns with the mean value of the column\n",
    "    \"\"\"\n",
    "    features, label = line[0], line[1]\n",
    "    imputed_features = []\n",
    "    for i, value in enumerate(features):\n",
    "        if i < 13: \n",
    "            if value == 'null':\n",
    "                imputed_features.append(mean_or_median_dict[i])\n",
    "            else:\n",
    "                imputed_features.append(value)\n",
    "        else: \n",
    "            imputed_features.append(value)\n",
    "    return (imputed_features, int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# getting the median with pandas because RDDs don't have a built-in function \n",
    "medians = toy_df_num.median().tolist()\n",
    "median_dict_toy = dict(zip(mean_dict_toy.keys(), medians))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imputing nulls with median \n",
    "imputedToyRDDCached = toyRDDCached.map(lambda x: impute_nulls(x, median_dict_toy)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imputedToyRDDCached.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.13.2 Standardize features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize(line, mean_dict, st_dev_dict):\n",
    "    \"\"\"\n",
    "    Scale and center data round mean of each feature (mean=0, sd=1)\n",
    "    \"\"\"\n",
    "    features, label = line[0], line[1]\n",
    "    formated_features = []\n",
    "    for i, value in enumerate(features):\n",
    "        if i < 13: \n",
    "            formated_features.append((value-mean_dict[i])/st_dev_dict[i])\n",
    "        else: \n",
    "            formated_features.append(value)\n",
    "\n",
    "    return (formated_features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TOY DATA \n",
    "normedToyRDDCached = imputedToyRDDCached.map(lambda x: standardize(x, mean_dict_toy, st_dev_dict_toy)).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.13.3 Bucketing Categorical features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will demonstrate how the bucketing/one-hot encoding that was applied in a scalable manner to our Criteo dataset, using our toy dataset with 1000 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use variable `C1` as an example to demonstrate the implementation. The analysis above showed that variable `C1` has 57 uniques categories, hence we will obtain the occurence counts for each of the 57 categories in `C1`. Each of these categories will then be placed in one of the 4 buckets mentioned above based on its occurence counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**. Obtain the occurence counts for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1 has var_position = 13\n",
    "category_counts_C1 = normedToyRDDCached.map(lambda x: ( x[0][13], 1)) \\\n",
    "                                       .reduceByKey(lambda x,y: x+y) \\\n",
    "                                       .sortBy(lambda x: -x[1])\n",
    "\n",
    "category_counts_C1.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**. Classify each category into one of the 4 buckets mentioned above based on its occurence counts and broadcast this information. As we learned throughout the semester, broadcasted variables are very useful in cases where the programmer wants to pass a copy of some useful information to every node in an efficient manner. \n",
    "\n",
    "* `>=` 100 times (i.e. 10% of 1000 rows) -> *High frequency* \n",
    "* 20-100 times (i.e. 2-10% of 1000 rows) -> *Medium frequency* \n",
    "* `<`20 times (i.e. 2% of 1000 rows) -> *Low frequency* \n",
    "* `==` 'null' -> *Missing*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# applying on C1 only \n",
    "high_frequency_categorices_C1 = sc.broadcast(category_counts_C1.filter(lambda x: x[1] >= 100).map(lambda x: x[0]).collect())\n",
    "medium_frequency_categorices_C1 = sc.broadcast(category_counts_C1.filter(lambda x: x[1] < 100 and x[1] >= 20).map(lambda x: x[0]).collect())\n",
    "low_frequency_categorices_C1 = sc.broadcast(category_counts_C1.filter(lambda x: x[1] < 20).map(lambda x: x[0]).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1 \n",
    "print('High frequency categories: {} \\n'.format(high_frequency_categorices_C1.value))\n",
    "print('Medium frequency categories: {} \\n'.format(medium_frequency_categorices_C1.value))\n",
    "print('Low frequency categories: {} \\n'.format(low_frequency_categorices_C1.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.** Applying a homegrown one-hot encoding implementation as explained above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# C1 example: the new columns of our dataset now are\n",
    "FIELDS_NEW_C1 = ['I1','I2','I3','I4','I5','I6','I7','I8','I9','I10','I11','I12','I13',          # numerical \n",
    "          'High_Freq_C1','Medium_Freq_C1','Low_Freq_C1','Missing_C1',      # categorical \n",
    "          'Label']                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OHE_transform(line, cat_var_position, high_frequency_categorices, medium_frequency_categorices, low_frequency_categorices):\n",
    "    \"\"\"\n",
    "    One hot encoding transformation of an RDD \n",
    "    using the high/medium/low/missing logic\n",
    "    \n",
    "    returns: (ohe_transformed_features, label)\n",
    "    \"\"\"\n",
    "    features, label = line[0], line[1]\n",
    "    cat_features = []\n",
    "    num_features = []\n",
    "    for i, value in enumerate(features):\n",
    "        if i > 12 and i < 39: \n",
    "            cat_features.append(value)\n",
    "        else:\n",
    "            num_features.append(value)\n",
    "\n",
    "    # define the cat_var_position here \n",
    "    high_freq = 1 if any(i in cat_features[cat_var_position] for i in high_frequency_categorices.value) else 0\n",
    "    medium_freq = 1 if any(i in cat_features[cat_var_position] for i in medium_frequency_categorices.value) else 0\n",
    "    low_freq = 1 if any(i in cat_features[cat_var_position] for i in low_frequency_categorices.value) else 0\n",
    "    missing = 1 if any(i in cat_features[cat_var_position] for i in ['null']) else 0\n",
    "    ohe_features = [high_freq] + [medium_freq] + [low_freq] + [missing]\n",
    "\n",
    "    return (num_features + ohe_features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transforming RDD for C1 \n",
    "var_position = 13\n",
    "cat_var_position = 0\n",
    "oheTrasformedToyRDDCached_C1 = normedToyRDDCached.map(lambda x: OHE_transform(x, cat_var_position, high_frequency_categorices_C1, medium_frequency_categorices_C1, low_frequency_categorices_C1)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(oheTrasformedToyRDDCached_C1.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**. Transform all 26 categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oheTrasformedToyRDDCached_all = oheTrasformedToyRDDCached_C1\n",
    "\n",
    "for cat_var_position in list(range(1,26)):\n",
    "    \n",
    "    category_counts_C_i = normedToyRDDCached.map(lambda x: ( x[0][cat_var_position+13], 1)) \\\n",
    "                                       .reduceByKey(lambda x,y: x+y) \\\n",
    "                                       .sortBy(lambda x: -x[1])\n",
    "    \n",
    "    high_frequency_categorices_C_i = sc.broadcast(category_counts_C_i.filter(lambda x: x[1] >= 100).map(lambda x: x[0]).collect())\n",
    "    medium_frequency_categorices_C_i = sc.broadcast(category_counts_C_i.filter(lambda x: x[1] < 100 and x[1] >= 20).map(lambda x: x[0]).collect())\n",
    "    low_frequency_categorices_C_i = sc.broadcast(category_counts_C_i.filter(lambda x: x[1] < 20).map(lambda x: x[0]).collect())\n",
    "\n",
    "    oheTrasformedToyRDDCached_C_i = normedToyRDDCached.map(lambda x: OHE_transform(x, cat_var_position, high_frequency_categorices_C_i, medium_frequency_categorices_C_i, low_frequency_categorices_C_i)).cache()\n",
    "    \n",
    "    oheTrasformedToyRDDCached_all = oheTrasformedToyRDDCached_all.zip(oheTrasformedToyRDDCached_C_i.map(lambda x: x[0][13:])).map(lambda x: (x[0][0]+x[1], x[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(oheTrasformedToyRDDCached_all.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_col_names = []\n",
    "\n",
    "for i in list(range(1,27)):\n",
    "    cat_col_names.append('High_Freq_C'+str(i))\n",
    "    cat_col_names.append('Medium_Freq_C'+str(i))\n",
    "    cat_col_names.append('Low_Freq_C'+str(i))\n",
    "    cat_col_names.append('Missing'+str(i))\n",
    "    \n",
    "FIELDS_NEW = ['I1','I2','I3','I4','I5','I6','I7','I8','I9','I10','I11','I12','I13'] + cat_col_names + ['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FIELDS_NEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...Caching toy train and test RDDs post data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toyTrainRDD = oheTrasformedToyRDDCached_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply the same data transformations to the toy held-out dataset, using the parameters from the train toy set (i.e. median for imputation, mean and st. deviation for standardization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...Data transformation of the toy Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transforming the test toy data using the train data parameters \n",
    "# toy_testRDD = sc.textFile('data/toy_test300.txt')\n",
    "toyTestRDDCached = toy_testRDD.map(parse).map(edit_data_types).cache()\n",
    "imputedToyTestRDDCached = toyTestRDDCached.map(lambda x: impute_nulls(x, median_dict_toy)).cache()\n",
    "normedToyTestRDDCached = imputedToyTestRDDCached.map(lambda x: standardize(x, mean_dict_toy, st_dev_dict_toy)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transforming categorical features for test toy RDD using parameters obtained for train RDDs \n",
    "\n",
    "# initialize to get C1\n",
    "var_position = 13\n",
    "cat_var_position = 0\n",
    "oheTrasformedToyTestRDDCached_C1 = normedToyTestRDDCached.map(lambda x: OHE_transform(x, cat_var_position, high_frequency_categorices_C1, medium_frequency_categorices_C1, low_frequency_categorices_C1)).cache()\n",
    "\n",
    "# get transformed features for full data \n",
    "oheTrasformedToyTestRDDCached_all = oheTrasformedToyTestRDDCached_C1\n",
    "\n",
    "for cat_var_position in list(range(1,26)):\n",
    "    \n",
    "    category_counts_C_i = normedToyRDDCached.map(lambda x: ( x[0][cat_var_position+13], 1)) \\\n",
    "                                       .reduceByKey(lambda x,y: x+y) \\\n",
    "                                       .sortBy(lambda x: -x[1])\n",
    "    \n",
    "    high_frequency_categorices_C_i = sc.broadcast(category_counts_C_i.filter(lambda x: x[1] >= 100).map(lambda x: x[0]).collect())\n",
    "    medium_frequency_categorices_C_i = sc.broadcast(category_counts_C_i.filter(lambda x: x[1] < 100 and x[1] >= 20).map(lambda x: x[0]).collect())\n",
    "    low_frequency_categorices_C_i = sc.broadcast(category_counts_C_i.filter(lambda x: x[1] < 20).map(lambda x: x[0]).collect())\n",
    "\n",
    "    oheTrasformedToyTestRDDCached_C_i = normedToyTestRDDCached.map(lambda x: OHE_transform(x, cat_var_position, high_frequency_categorices_C_i, medium_frequency_categorices_C_i, low_frequency_categorices_C_i)).cache()\n",
    "    \n",
    "    oheTrasformedToyTestRDDCached_all = oheTrasformedToyTestRDDCached_all.zip(oheTrasformedToyTestRDDCached_C_i.map(lambda x: x[0][13:])).map(lambda x: (x[0][0]+x[1], x[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toyTestRDD = oheTrasformedToyTestRDDCached_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(toyTestRDD.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...Transform toy RDD train and test sets to pandas DataFrames:\n",
    "These will be used in section 3B for training and validating the homegrown Random Forest implementation in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toyTrainRDDtoPandas = toyTrainRDD.map(null_to_nan).map(lambda x: np.append(x[0], [x[1]])).collect()\n",
    "toyTestRDDtoPandas = toyTestRDD.map(null_to_nan).map(lambda x: np.append(x[0], [x[1]])).collect()\n",
    "\n",
    "toy_train_df = pd.DataFrame(toyTrainRDDtoPandas, columns=FIELDS_NEW) \n",
    "toy_test_df = pd.DataFrame(toyTestRDDtoPandas, columns=FIELDS_NEW) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toy_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Algorithm Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals for this section:\n",
    "\n",
    "#### PART A: Logistic Regression\n",
    "\n",
    "Build a home grown implementation of Logisitc Regression using RDDs\n",
    "\n",
    "#### PART B: Random Forest\n",
    "\n",
    "Build a home grown implementation of Random Forest using Python. \n",
    "\n",
    "### Why did we choose these two models?\n",
    "\n",
    "Given scalability concerns and the need for feature selection, we decided to explore two independent models to assess the optimal performance. We also wanted to identify algorithms that have a history of success in the Spark framework for binary classification. Logistic Regression and Decision Trees met all of these criteria. Logistic Regession is highly scalable and combined with regularization could aid in feature selection. Decision trees have similar benefits and additionally require little pre-processing and any prior feature selection. We continued down these parallel paths to compare the performance of these models.\n",
    "\n",
    "### Baseline: \n",
    "\n",
    "Our baseline is at 74.38% (which is majority of class 0 in train dataset). We will be bechmarking our models' accuracy and performance results in comparison with this baseline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART A: Logisitc Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Homegrown implementation of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the baseline model\n",
    "BASELINE_1 = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "#BASELINE_2 = np.array([meanClickthroughs, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute log loss for Logisitc Regression\n",
    "def LRLoss(cachedRDD, W):\n",
    "    augmentedData = cachedRDD.map(lambda x: (np.append([1.0], x[0]), x[1]))\n",
    "    loss = augmentedData.map(lambda x: -x[1] * np.log(1/ (1 + np.exp(-(np.dot(x[0],W))))) - (1-x[1]) * np.log(1-(1/ (1 + np.exp(-(np.dot(x[0],W))))))).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using meanClickthroughs as our bias term improves loss significantly (it will be used in our baseline)\n",
    "\n",
    "train_loss_baseline1 = LRLoss(normedRDD_train, BASELINE_1)\n",
    "print(\"Train Loss using 0 for baseline\", train_loss_baseline1)\n",
    "\n",
    "train_loss_baseline2 = LRLoss(normedRDD_train, BASELINE_2)\n",
    "print(\"Train Loss using meanClickthroughs as baseline\", train_loss_baseline2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BASELINE = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "# np.zeros(47)\n",
    "BASELINE = np.array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the gradient for logistic regression (one step)\n",
    "def GDUpdate(dataRDD, W, learningRate):\n",
    "    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1])).cache()\n",
    "    grad = augmentedData.map(lambda x: np.dot(x[0], ((1/ (1 + np.exp(-(np.dot(x[0],W))))) - x[1]))).mean()\n",
    "    new_model = W - (learningRate * grad)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform one Gradient Descent update with lasso regularization\n",
    "def GDUpdate_Lasso(dataRDD, W, learningRate, regParam):\n",
    "\n",
    "    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1])).cache()\n",
    "    #new_model = None    \n",
    "    wReg = np.sign(W)\n",
    "    wReg[0] = 0  #set bias to zero\n",
    "       \n",
    "    grad = augmentedData.map(lambda x: np.dot(x[0], ((1/ (1 + np.exp(-(np.dot(x[0],W))))) - x[1]))).mean() + (wReg * regParam)\n",
    "    new_model = W - (learningRate * grad)\n",
    "    \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = GDUpdate_Lasso(toyTrainRDD, BASELINE, .1, .1)\n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_and_score(dataRDD, W, threshold):\n",
    "    \"\"\"Assess peformance of current models\"\"\"\n",
    "    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1]))\n",
    "        \n",
    "    sc.broadcast(W)\n",
    "    sc.broadcast(threshold)\n",
    "\n",
    "    def predict_label(line):\n",
    "        features = line[0]\n",
    "        label = line[1]\n",
    "        pred = None\n",
    "        z = np.dot(features,W)\n",
    "        prob = np.divide(1.0, (1.0 + np.exp(-z)))\n",
    "        if prob > threshold:\n",
    "            pred = float(1.0)\n",
    "        else:\n",
    "            pred = float(0.0)\n",
    "        return label, pred\n",
    "        \n",
    "    def map_accuracy(line):\n",
    "        label_actual = line[0]        \n",
    "        label_pred = line[1]\n",
    "        \n",
    "        if label_actual == 1.0 and label_pred == 1.0:\n",
    "            return \"TP\", 1.0\n",
    "        elif label_actual == 1.0 and label_pred == 0.0:\n",
    "            return \"FN\", 1.0\n",
    "        elif label_actual == 0.0 and label_pred == 0.0:\n",
    "            return \"TN\", 1.0\n",
    "        else:\n",
    "            if label_actual == 0.0 and label_pred == 1.0:\n",
    "                return \"FP\", 1.0\n",
    "    \n",
    "    scores = augmentedData.map(predict_label).map(map_accuracy).reduceByKey(lambda x, y: x + y).collect()\n",
    "    \n",
    "    TP, FN, TN, FP = 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    for i in scores:\n",
    "        if i[0] == 'TP':\n",
    "            TP = i[1]\n",
    "        elif i[0] == 'FN':\n",
    "            FN = i[1]\n",
    "        elif i[0] == 'TN':\n",
    "            TN = i[1]\n",
    "        else:\n",
    "            if i[0] == 'FP':\n",
    "                FP = i[1]\n",
    "\n",
    "    if TP != 0.0:\n",
    "        precision = TP/(TP + FP)\n",
    "        recall = TP/(TP + FN)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "        false_positive_rate = FP/(FP+TN)\n",
    "        \n",
    "    else:\n",
    "        precision = 0.0\n",
    "        recall = 0.0\n",
    "        f1_score = 0.0\n",
    "        accuracy = 0.0\n",
    "        false_positive_rate = 0.0\n",
    "\n",
    "#     print(\"scores=\", scores)\n",
    "#     print(\"True Positives=\", TP)\n",
    "#     print(\"False Negatives=\", FN)\n",
    "#     print(\"True Negatives=\", TN)\n",
    "#     print(\"False Positives=\", FP)\n",
    "#     print(\"Precision=\", precision)\n",
    "#     print(\"Recall=\", recall)\n",
    "#     print(\"F1_score=\", f1_score)\n",
    "#     print('Accuracy=', accuracy)\n",
    "\n",
    "    return accuracy, precision, recall, f1_score, false_positive_rate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updated_model = GDUpdate_Lasso(toyTrainRDD, BASELINE, .1, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_score(toyTrainRDD, updated_model, threshold=.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GradientDescent(trainRDD, testRDD, wInit, nSteps = 20, \n",
    "                    learningRate = 0.1, verbose = True):\n",
    "    \"\"\"\n",
    "    Perform nSteps iterations of Logistic Regression gradient descent and \n",
    "    track performance metrics on the test and train set. \n",
    "    \"\"\"\n",
    "    # initialize lists to track model performance\n",
    "    train_history, test_history, model_history = [], [], []\n",
    "    accuracies, f1_scores, precisions, recalls, false_positive_rates = [], [], [], [], []\n",
    "    \n",
    "    # perform n updates & compute test and train loss after each\n",
    "    model = wInit\n",
    "    for idx in range(nSteps): \n",
    "        \n",
    "        ############## CORE CODE #############\n",
    "        \n",
    "        new_model = GDUpdate(trainRDD, model, learningRate=0.1)\n",
    "        training_loss = LRLoss(trainRDD, new_model)\n",
    "        test_loss = LRLoss(testRDD, new_model)\n",
    "        accuracy, precision, recall, f1_score, false_positive_rate = predict_and_score(toyTrainRDD, new_model, threshold=.55)\n",
    "        \n",
    "        model = new_model\n",
    "        \n",
    "        ############## (END) CORE CODE #############\n",
    "        \n",
    "        # keep track of metrics for plotting\n",
    "        train_history.append(training_loss)\n",
    "        test_history.append(test_loss)\n",
    "        model_history.append(model)\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1_score)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        false_positive_rates.append(false_positive_rate)\n",
    "        \n",
    "        # console output\n",
    "        if verbose:\n",
    "            print(\"----------\")\n",
    "            print(f\"STEP: {idx+1}\")\n",
    "            print(f\"training loss: {training_loss}\")\n",
    "            print(f\"test loss: {test_loss}\")\n",
    "            print(f\"Accuracy: {accuracy}\")\n",
    "            print(f\"Precision: {precision}\")\n",
    "            print(f\"Recall: {recall}\")\n",
    "            print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "            print(f\"Model: {[round(w,3) for w in model]}\")\n",
    "    return train_history, test_history, model_history, accuracies, f1_scores, precisions, recalls, false_positive_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 50 iterations (RUN THIS CELL AS IS)\n",
    "wInit = BASELINE\n",
    "#trainRDD, testRDD = normedRDD.randomSplit([0.8,0.2], seed = 2018)\n",
    "start = time.time()\n",
    "logLossTrain, logLossTest, model_history, accuracy, f1_score, precision, recall, false_positive_rate = GradientDescent(toyTrainRDD, toyTestRDD, wInit, nSteps = 30)\n",
    "print(f\"\\n... trained {30} iterations in {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotErrorCurves(trainLoss, testLoss, title = None):\n",
    "    \"\"\"\n",
    "    Helper function for plotting.\n",
    "    Args: trainLoss (list of MSE) , testLoss (list of MSE)\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1,1,figsize = (16,8))\n",
    "    x = list(range(len(trainLoss)))[1:]\n",
    "    ax.plot(x, trainLoss[1:], 'k--', label='Training Loss') #trainLoss[1:]\n",
    "    ax.plot(x, testLoss[1:], 'r--', label='Test Loss')\n",
    "\n",
    "    ax.legend(loc='upper right', fontsize='x-large')\n",
    "    plt.xlabel('Number of Iterations')\n",
    "    plt.ylabel('Performance')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_LogLoss_learningRate_point2 = plotErrorCurves(logLossTrain, logLossTest, title = 'Logisitic Regression LogLoss Trend')\n",
    "LR_LogLoss_learningRate_point2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_LogLoss_lasso = plotErrorCurves(logLossTrain, logLossTest, title = 'Logisitic Regression LogLoss Trend')\n",
    "LR_LogLoss_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_Loss_original = plotErrorCurves(logLossTrain, logLossTest, title = 'Logisitic Regression LogLoss Trend')\n",
    "LR_Loss_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotPerformance(accuracy, f1_score, title = None):\n",
    "    \"\"\"\n",
    "    Helper function for plotting.    \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1,1,figsize = (16,8))\n",
    "    x = list(range(len(accuracy)))[1:]\n",
    "    ax.plot(x, accuracy[1:], 'r--', label='Accuracy')\n",
    "    ax.plot(x, f1_score[1:], 'k--', label='F1_score')\n",
    "    #ax.plot(x, precision[1:], 'g--', label='Precision')\n",
    "    #ax.plot(x, recall[1:], 'b--', label='Recall')\n",
    "\n",
    "    ax.legend(loc='upper right', fontsize='x-large')\n",
    "    plt.xlabel('Number of Iterations')\n",
    "    plt.ylabel('Performance')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    #precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_performance_learningRate_point2 = plotPerformance(accuracy, f1_score, title = 'Logisitic Regression Performance - learning rate .2')\n",
    "LR_performance_learningRate_point2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_performance_lasso = plotPerformance(accuracy, f1_score, title = 'Logisitic Regression Performance - Lasso')\n",
    "LR_performance_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_performance_original = plotPerformance(accuracy, f1_score, title = 'Logisitic Regression Performance - Original')\n",
    "LR_performance_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotROCcurves(recall, false_positive_rate, title = None):\n",
    "    \"\"\"\n",
    "    Helper function for plotting.    \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1,1,figsize = (16,8))\n",
    "    #x = list(range(len(recall)))[1:]\n",
    "    #y = list(range(len(false_positive_rate)))[1:]\n",
    "    \n",
    "    #ax.plot(false_positive_rate[1:], recall[1:], 'r--', label='False Positive Rate')\n",
    "\n",
    "    ax.plot(false_positive_rate, recall, 'r--')\n",
    "\n",
    "    #ax.plot(x, false_positive_rate[1:], 'r--', label='False Positive Rate')\n",
    "    #ax.plot(y, recall[1:], 'k--', label='True Positive Rate')\n",
    "\n",
    "    #ax.legend(loc='upper right', fontsize='x-large')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_learning_rate2 = plotROCcurves(recall, false_positive_rate, title = \"ROC Curve - learning rate = .2\")\n",
    "ROC_learning_rate2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_lasso = plotROCcurves(recall, false_positive_rate, title = \"ROC Curve - Lasso\")\n",
    "ROC_lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_original = plotROCcurves(recall, false_positive_rate, title = \"ROC Curve - original\")\n",
    "ROC_original "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART B: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Random Forest (RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Random Forest Algorithm Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest:\n",
    "    \n",
    "1. Why we chose RF for this data set?\n",
    "2. Concepts of RF:\n",
    "3. How does the home grown implementation work? + Flow diagram\n",
    "4. Tuning parameters used\n",
    "5. Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Homegrown Implementation of RF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using transformed toy datasets from above as pandas Dataframes\n",
    "toy_dataset = toy_train_df.values.tolist()\n",
    "toy_test_dataset = toy_test_df.values.tolist()\n",
    "\n",
    "print(toy_datatset[0])\n",
    "print(toy_test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "        dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        if row[column] == 'null':\n",
    "            row[column] = None\n",
    "        else:\n",
    "            row[column] = float(row[column].strip())\n",
    "\n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    # useful if label column coming as categories\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i \n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    " \n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            # gives one random number\n",
    "            index = randrange(len(dataset_copy))\n",
    "            # pop this random number from dataset\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        # add fold generated to list of folds\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    " \n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    " \n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    global flag\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for i,fold in enumerate(folds):\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        # Converting list of lists to list\n",
    "        # Ex. converts [[1],[2],[3]] to [1,2,3]\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            # Setting the label to None in test set\n",
    "            row_copy[-1] = None\n",
    "            test_set.append(row_copy)\n",
    "        trees, predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = round(accuracy_metric(actual, predicted),4)\n",
    "        scores.append(accuracy)\n",
    "        # using these flags so that the graph will have the nodes of one tree only and will not merge mutliple trees\n",
    "        if i == len(folds)-1 and flag==1:\n",
    "            decisiontree= trees[0]\n",
    "            visit(decisiontree, 0) \n",
    "            #graph.write_png('decision_tree_graph.png')  \n",
    "            print(\"Sample Decision Tree Graph:\\n\\n\", graph)\n",
    "            flag = 2\n",
    "            #print(yaml.dump(decisiontree, default_flow_style=False)) \n",
    "            print(\"Sample Decision Tree Nested Dictionary:\\n\\n\", decisiontree)\n",
    "    return scores\n",
    " \n",
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    # index here is the column index in dataset\n",
    "    # value is the column/feature value based on which split has to be done \n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    " \n",
    "# Calculate the Gini index for a split dataset\n",
    "def gini_index(groups, classes): \n",
    "    # classes: number of output/label classes\n",
    "    # number of split branches at a split \n",
    "    # ex. if groups = 2, meaning left and right node of the splits\n",
    "    \n",
    "    # count all samples at split point\n",
    "    # total number of samples in left and right nodes \n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    # sum weighted Gini index for each group\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        # avoid divide by zero - if there are no samples in a node\n",
    "        if size == 0: \n",
    "            continue\n",
    "        score = 0.0\n",
    "        # score the group based on the score for each class\n",
    "        node_labels = [row[-1] for row in group]\n",
    "        for class_val in classes:\n",
    "            # count the no. of samples of class = 1,0 etc. \n",
    "            p = node_labels.count(class_val) / size\n",
    "            # calculate unweighted gini index\n",
    "            score += p * (1-p)\n",
    "        # weight the group score by its relative size\n",
    "        # calculate gini index by weighing by the number of instances\n",
    "        gini += score * (size / n_instances)\n",
    "    return gini\n",
    " \n",
    "# Select the best split point for a dataset\n",
    "def get_split(dataset, n_features):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    features = list()\n",
    "    while len(features) < n_features:\n",
    "        index = randrange(len(dataset[0])-1)\n",
    "        if index not in features:\n",
    "            features.append(index)\n",
    "    for index in features:\n",
    "        # Get unique set of values for a feature (index)\n",
    "        unique_values = set([row[index] for row in dataset])\n",
    "        # use test split to get the distribution of nodes for each value \n",
    "        # get gini index of this test split \n",
    "        for value in unique_values:\n",
    "            # groups here are the left and right node samples after splitting on the value\n",
    "            groups = test_split(index, value, dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, value, gini, groups\n",
    "    # returns a node with the index with which it has to be split, value and two groups after split\n",
    "    features_importance[str(FIELDS[b_index])] += float(b_score)\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    " \n",
    "# Create a terminal node value\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    # set the label of the terminal node to be the dominant label of the node samples based on count\n",
    "    return max(set(outcomes), key=outcomes.count)\n",
    " \n",
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, n_features, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # check for a no split\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left, n_features)\n",
    "        split(node['left'], max_depth, min_size, n_features, depth+1)\n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right, n_features)\n",
    "        split(node['right'], max_depth, min_size, n_features, depth+1)\n",
    "\n",
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size, n_features):\n",
    "    root = get_split(train, n_features)\n",
    "    # split is called on the root node to iteratively build the tree\n",
    "    split(root, max_depth, min_size, n_features, 1)\n",
    "    return root # this will have the entire tree\n",
    " \n",
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "    # node here will be the root node\n",
    "    if row[node['index']] < node['value']:\n",
    "        # if the left branch is a node\n",
    "        # call predict again to pass row down that node\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "        # else if it is terminal node, just return the label value\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "# Create a random subsample from the dataset with replacement\n",
    "def subsample(dataset, ratio):\n",
    "    sample = list()\n",
    "    n_sample = round(len(dataset) * ratio)\n",
    "    while len(sample) < n_sample:\n",
    "        index = randrange(len(dataset))\n",
    "        sample.append(dataset[index])\n",
    "    return sample\n",
    " \n",
    "# Make a prediction with a list of bagged trees\n",
    "def bagging_predict(trees, row):\n",
    "    predictions = [predict(tree, row) for tree in trees]\n",
    "    return max(set(predictions), key=predictions.count)\n",
    "\n",
    "# Building a tree traversal and graph structure for visualization \n",
    "def visit(node, depth, parent = None):\n",
    "    feature=node['index']\n",
    "    feature = FIELDS[feature]\n",
    "    feature_value=node['value']\n",
    "    left_node = node['left']\n",
    "    right_node = node['right']\n",
    "    child_nodes = [left_node, right_node]\n",
    "    \n",
    "    if depth ==0:            \n",
    "        node_root = \"D\"+str(depth)+\"_\"+str(feature)\n",
    "    else:\n",
    "        parent = FIELDS[parent]\n",
    "        node_root = \"D\"+str(depth)+\"_\"+str(parent)\n",
    "    \n",
    "    # processing left_child\n",
    "    if isinstance(left_node, dict):\n",
    "        node_child = \"D\"+str(depth+1)+\"_\"+str(FIELDS[left_node['index']])\n",
    "        graph.add_edge(pydot.Edge(node_root, node_child, label=\"L \"+str(feature_value)))\n",
    "        visit(left_node,depth+1, parent=left_node['index'])\n",
    "    else:\n",
    "        node_terminal = \"D\"+str(depth+1)+\"_Class_\"+str(left_node)\n",
    "        graph.add_edge(pydot.Edge(node_root, node_terminal, label=\"L \"+str(feature_value)))\n",
    "    \n",
    "    # processing right_child\n",
    "    if isinstance(right_node, dict):\n",
    "        node_child = \"D\"+str(depth+1)+\"_\"+str(FIELDS[right_node['index']])\n",
    "        graph.add_edge(pydot.Edge(node_root, node_child, label='R '+str(feature_value)))\n",
    "        visit(right_node,depth+1, parent=right_node['index'])\n",
    "    else:\n",
    "        node_terminal = \"D\"+str(depth+1)+\"_Class_\"+str(right_node)\n",
    "        graph.add_edge(pydot.Edge(node_root, node_terminal, label=\"R \"+str(feature_value)))\n",
    "\n",
    "\n",
    "# Random Forest Algorithm\n",
    "def random_forest(train, test, max_depth, min_size, sample_size, n_trees, n_features):\n",
    "    trees = list()\n",
    "    for i in range(n_trees):\n",
    "        sample = subsample(train, sample_size)\n",
    "        decisiontree = build_tree(sample, max_depth, min_size, n_features)\n",
    "        trees.append(decisiontree)\n",
    "    predictions = [bagging_predict(trees, row) for row in test]\n",
    "    return(trees, predictions)\n",
    "\n",
    "\n",
    "# get_accuracy\n",
    "def get_accuracy(dataset, n_trees, n_folds,  max_depth, min_size):\n",
    "    accuracy_list = []\n",
    "    global flag\n",
    "    global features_importance\n",
    "    print(\"N-folds:\", n_folds, \" Max_depth:\", max_depth, \" Min size:\", min_size, \"\\n\")\n",
    "    for n_trees in number_of_trees:\n",
    "        start = time.time()\n",
    "        scores = evaluate_algorithm(dataset, random_forest, n_folds, max_depth, min_size, sample_size, n_trees, n_features)\n",
    "        print('\\nTrees: %d' % n_trees)\n",
    "        print('Scores: %s' % scores)\n",
    "        accuracy = round((sum(scores)/float(len(scores))),4)\n",
    "        accuracy_list.append(accuracy)\n",
    "        print('Mean Accuracy: %.3f%%' % accuracy)\n",
    "        print('Training time:', time.time()-start, ' seconds')\n",
    "    # setting flag back to 1 for next call of get_accuracy\n",
    "    flag = 1\n",
    "    features_importance = sorted(features_importance.items(), key=operator.itemgetter(1))\n",
    "    features_importance = [(item[0],round(item[1],2)) for item in features_importance]\n",
    "    print('\\nFeatures in decreasing order of importance:\\n\\nSummed gini index for a feature across all trees - lower the gini index the better\\n\\n', features_importance)\n",
    "    features_importance = defaultdict(float)\n",
    "    graph = pydot.Dot(graph_type='digraph')\n",
    "    flag = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Training and Testing Homegrown RF on Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_size = 1.0\n",
    "n_features = int(sqrt(len(dataset[0])-1))\n",
    "number_of_trees = [1, 5, 10]#, 20, 30, 40, 50, 75,100,]#200]\n",
    "features_importance = defaultdict(float)\n",
    "\n",
    "print('\\n Accuracy of RF on Toy Train Dataset:\\n--------------------------------------\\n')\n",
    "get_accuracy(dataset = toy_dataset, n_trees = number_of_trees, n_folds = 3, max_depth = 7, min_size = 10)\n",
    "\n",
    "print('\\n Accuracy of RF on Toy Test Dataset:\\n--------------------------------------\\n')\n",
    "get_accuracy(dataset = toy_test_dataset, n_trees = number_of_trees, n_folds = 3, max_depth = 7, min_size = 10)\n",
    "\n",
    "# display sample decision tree built\n",
    "Image(filename=\"decision_tree_graph.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Comparing RF Accuracy with various Tuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plotting graphs \n",
    "plt.figure(figsize=(15,5),) \n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Accuracy of Random Forest vs Number of Trees \\n Number of Folds = 3, Varying Depth, Fixed Min.Size\")\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Classification Accuracy')\n",
    "plt.plot(number_of_trees, get_accuracy(dataset = toy_dataset, n_trees = number_of_trees, n_folds = 3, max_depth = 5, min_size = 20), color='red')\n",
    "plt.plot(number_of_trees, get_accuracy(dataset = toy_dataset, n_trees = number_of_trees, n_folds = 3, max_depth = 7, min_size = 20), color='aqua')\n",
    "plt.plot(number_of_trees, get_accuracy(dataset = toy_dataset, n_trees = number_of_trees, n_folds = 3, max_depth = 9, min_size = 20), color='darkorchid')\n",
    "plt.plot(number_of_trees, get_accuracy(dataset = toy_dataset, n_trees = number_of_trees, n_folds = 3, max_depth = 11, min_size = 20), color = 'lime')\n",
    "red_patch = mpatches.Patch(color='red', label='depth=5 min_size=20')\n",
    "aqua_patch = mpatches.Patch(color='aqua', label='depth=7 min_size=20')\n",
    "darkorchid_patch =  mpatches.Patch(color='darkorchid', label='depth=9 min_size=20')\n",
    "lime_patch =  mpatches.Patch(color='lime', label='depth=11 min_size=20')\n",
    "plt.legend(handles=[red_patch, aqua_patch, darkorchid_patch, lime_patch])\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Accuracy of Random Forest vs Number of Trees \\n Number of Folds = 3, Depth=5,7, Varying Min.Size\")\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Classification Accuracy')\n",
    "plt.plot(number_of_trees, get_accuracy(dataset = toy_dataset, n_trees = number_of_trees, n_folds = 3, max_depth = 5, min_size = 20), color='red')\n",
    "plt.plot(number_of_trees, get_accuracy(dataset = toy_dataset, n_trees = number_of_trees, n_folds = 3, max_depth = 5, min_size = 10), color='aqua')\n",
    "plt.plot(number_of_trees, get_accuracy(dataset = toy_dataset, n_trees = number_of_trees, n_folds = 3, max_depth = 7, min_size = 20), color='darkorchid')\n",
    "plt.plot(number_of_trees, get_accuracy(dataset = toy_dataset, n_trees = number_of_trees, n_folds = 3, max_depth = 7, min_size = 10), color = 'lime')\n",
    "red_patch = mpatches.Patch(color='red', label='depth=5 min_size=20')\n",
    "aqua_patch = mpatches.Patch(color='aqua', label='depth=5 min_size=10')\n",
    "darkorchid_patch =  mpatches.Patch(color='darkorchid', label='depth=7 min_size=20')\n",
    "lime_patch =  mpatches.Patch(color='lime', label='depth=7 min_size=10')\n",
    "plt.legend(handles=[red_patch, aqua_patch, darkorchid_patch, lime_patch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5 RF Performance and Accuracy on Toy Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on tuning parameters:\n",
    " \n",
    "1. How long it takes to train \n",
    "2. What is the accuracy compared to baseline?\n",
    "3. How does accuracy change with various tuning parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.6 Scaling Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling RF:\n",
    "    \n",
    "4. Why is RF suitable for scaling?\n",
    "5. How to scale RF?\n",
    "6. Potential challenges while sclaing:\n",
    "7. Decision to use homegrown RF on toy but use Spark ML on full "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Algorithm Implementation - Using Full Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART A: DATA TRANSFORMATION USING DATAFRAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Data Transformation Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: How EDA data tranformations decisions were used for building pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART B: LR AND RF WITH SPARK ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 LR in Spark ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 RF in Spark ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on Models:\n",
    "    1. Model training time details for LR and RF\n",
    "    2. Comparing accuracy for LR and RF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Application of Course Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Course Concepts:\n",
    "\n",
    "First List: \n",
    "1. Scalability\n",
    "2. Associative and Commutative \n",
    "3. No state dependency \n",
    "4. Algorithms chosen with this criteria\n",
    "5. Bias/Variance Tradeoff \n",
    "6. Regularization\n",
    "Updated:\n",
    "1. Scalability\n",
    "2. Associative/Commutative\n",
    "3. Statelessness\n",
    "4. GD - batch - Kim?\n",
    "5. Sparse representation - arvindh?\n",
    "6. Presenting the graph structure - anusha?\n",
    "7. One Hot encoding - Christina?\n",
    "8. Assumpations for Algorithsm - kim, anusha\n",
    "9. implications of iterative algorithms - arvindh spark vs hadoop\n",
    "\n",
    "Bias Variance Tradeoff\n",
    "Given the large number of features in this dataset, we needed to be careful not to overfit our data. A very complex model does not generalize well (high variance) while an overly simple model gives too much credit to the data itself (e.g., high bias: we believe too much in our data to do the work for us). These factors are introduced in model selection. We therefore explored two models (Logistic Regression and Decision Trees) that each allow us to identify important features and also adjust for complexities to avoid overfitting. In Logistic Regression, we used Lasso Regularization to avoid overfitting and identify unimportant features (eg. features where the weights are driven to zero). Decision Trees can also be made simpler or more complex by adjusting the depth of the trees, and has specific tools to identify important features. Together these tools helped us to optimize our models.\n",
    "\n",
    "Normalization:\n",
    "Given that the features in the dataset are on widely different scales, we needed to standardize the data to avoid lending over importance to features with bigger values. This was more important for the logistic regression model as decision trees opened on splits of each variable rather than a weighting of variables relative to one another.\n",
    "\n",
    "Map Reduce Design/Broadcasting/Lazy Evaluation\n",
    "The map reduce design lends itself very well to this problem. Given that we can compute each record as a pair RDD (label and values), and that the operations are associative and commutative, each row can be computed independently. We can cache our RDDs and use Spark’s functional programming design and lazy evaluation to avoid multiple passes over the data at each step. In linear regression, broadcasting values such as medians (which cannot be obtained in the RDD) helps us to optimize the process as well.\n",
    "\n",
    "### 5.2 Conclusion:\n",
    "Accuracy of Models and Performance Notes:\n",
    "    \n",
    "### 5.3 Future Ideas for Implementation:\n",
    "\n",
    "**1. Correlation between features**\n",
    "In a logistic regression context, features should not be highly correlated with each other. We saw that in our case a lot of features were highly correlated. However, we didn't make any feature exclusions based on multicollinearity, since we focused more on our tree-based algorithm that is not affect by feature correlation. As a future improvement step, we would remove those highly correlated features before feeding into the LR model. \n",
    "\n",
    "**2. Imbalance of labels**\n",
    "Our classification labels were imbalanced (75% label=0, 25% label=1). This could potentially decrease our model performance. A future step that our team would take to improve performance would be to balance the classes using bootstrap random sampling. \n",
    "\n",
    "**3. Outliers & Skewness**\n",
    "One noticeable issue that could be addressed to enhance performance would be to treat some extreme outliers. When looking at our numeric feature distributions we noticed some high positive skews. One way to deal with this would be to put a 'ceiling' on the values of features that would not exceed 3 standard deviations of each variable. Additionally, we would like to try taking the log of the highly skewed numeric features to smooth out the skewed distributions. \n",
    "\n",
    "**4. Columns/rows with large % of missing values**\n",
    "Finally, we noticed that a few variables had a high % of missing values. Due to the fact that we dealt with missing values in our categorical feature transformations, we decided to not make any column exclusions. However, it would be a good idea to exclude those columns and even rows with a certain threshold percentage of missing values and evaluate model performance. It is likely that our performance could be improved by doing so. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
